---
title: "GLODAPv2_2021"
author: "Jens Daniel M체ller"
date:  "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  workflowr::wflow_html:
    number_sections: true
    toc_depth: 3
    toc_float:
      collapsed: false
editor_options:
  chunk_output_type: console
---

```{r parent, child = "/nfs/kryo/work/jenmueller/emlr_cant/utilities/setup_obs.Rmd"}
# this chunk runs the code stored in setup.Rmd
# if required, please refer to instructions given here:
# https://jdblischak.github.io/workflowr/articles/wflow-07-common-code.html
```

```{r define_paths}

path_glodapv2_2021  <- "/nfs/kryo/work/updata/glodapv2_2021/"
path_glodapv2_CRM  <- "/nfs/kryo/work/updata/glodapv2_CRM/"
path_crossover <- "/nfs/kryo/work/updata/glodapv2_crossover"

path_preprocessing  <- paste(path_root, "/observations/preprocessing/", sep = "")
```

```{r load_libraries_specific, include=FALSE}
library(lubridate)
library(ggrepel)
library(kableExtra)
```

# Read files

## Adjusted data

Main data source for this project is `GLODAPv2.2021_Merged_Master_File.csv` downloaded from `https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0237935/GLODAPv2.2021_Merged_Master_File.csv` on Aug 30, 2021.

```{r read_GLODAPv2_2021_merged_master_file}

GLODAP <-
  read_csv(
    paste(
      path_glodapv2_2021,
      "GLODAPv2.2021_Merged_Master_File_20210830.csv",
      sep = ""
    ),
    na = "-9999",
    col_types = cols(.default = col_double())
  )


GLODAP <- GLODAP %>%
  rename_with(~str_remove(., 'G2'))

```

## Adjustment table

```{r read_GLODAPv2_2021_adjustment_table}

GLODAP_adjustments <-
  read_csv(
    paste(
      path_glodapv2_2021,
      "GLODAPv2.2021_adjustments_last_updated_on_2021_05_10.csv",
      sep = ""
    ),
    na = c("-666", "-777", "-888", "-999"),
    skip = 2
  )

```

## Expocodes

```{r read_GLODAPv2_2021_expocodes_and_doi}

GLODAP_expocodes <-
  read_tsv(
    paste(
      path_glodapv2_2021,
      "EXPOCODES.txt",
      sep = ""
    ),
    col_names = c("cruise", "cruise_expocode")
  )

```

## Crossover tables

```{r read_crossover_tables}

# tables from glodapv2, provided by Steven van Heuven

glodapv2_xover_files <- fs::dir_ls(paste0(path_crossover, "/glodapv2"))

glodapv2_xover <- glodapv2_xover_files %>% 
  map_dfr(read_csv, .id = "parameter")

glodapv2_xover <- glodapv2_xover %>% 
  mutate(parameter = str_remove(parameter, ".csv"),
         parameter = str_sub(parameter, -3))


glodapv2_xover <- glodapv2_xover %>% 
  mutate(parameter = recode(parameter,
                            "ALK" = "talk",
                            "DIC" = "tco2",
                            "NO3" = "nitrate",
                            "_O2" = "oxygen",
                            "PO4" = "phosphate",
                            "SAL" = "salinity",
                            "SIL" = "silicate"))

# Note: In the files provided by Steven von Heuven
# the column names sigma_ratio and sigma_offset_sd were swapped

glodapv2_xover_absolute <- glodapv2_xover %>% 
  filter(parameter %in% c("salinity", "talk", "tco2")) %>% 
  select(parameter,
         offset = sigma_offset,
         offset_sd = sigma_ratio,
         cruise_A = CruiseA_EXPOCODE,
         cruise_B = CruiseB_EXPOCODE)

glodapv2_xover_ratio <- glodapv2_xover %>% 
  filter(!(parameter %in% c("salinity", "talk", "tco2"))) %>% 
  select(parameter,
         offset = sigma_offset_sd,
         offset_sd = sigma_ratio_sd,
         cruise_A = CruiseA_EXPOCODE,
         cruise_B = CruiseB_EXPOCODE)

glodapv2_xover <- bind_rows(
  glodapv2_xover_absolute,
  glodapv2_xover_ratio
)


rm(glodapv2_xover_files,
   glodapv2_xover_absolute, glodapv2_xover_ratio)

# tables created between glodapv2 and glodapv2.2021
# provided by Nico Lange

glodapv2_2021_xover_files <- fs::dir_ls(paste0(path_crossover, "/glodapv2_2021"))

glodapv2_2021_xover <- glodapv2_2021_xover_files %>% 
  map_dfr(readxl::read_excel)

glodapv2_2021_xover <- glodapv2_2021_xover %>%
  rename(parameter = Parameter) %>%
  mutate(parameter = recode(parameter,
                            "alkalinity" = "talk")) %>%
  filter(
    parameter %in%
      c(
        "tco2",
        "nitrate",
        "oxygen",
        "phosphate",
        "salinity",
        "silicate",
        "talk"
      )
  )


glodapv2_2021_xover <- glodapv2_2021_xover %>% 
  rename(offset = Offset,
         offset_sd = Std,
         cruise_A = Cruise_A,
         cruise_B = Cruise_B)

rm(glodapv2_2021_xover_files)

# tables for data not qc'ed in the regular GLODAP release
# provided by Nico Lange

glodapv2_2021_xover_files_add <-
  fs::dir_ls(paste0(path_crossover, "/glodapv2_2021_additional_crossover"))

glodapv2_2021_xover_add <- glodapv2_2021_xover_files_add %>% 
  map_dfr(readxl::read_excel)

glodapv2_2021_xover_add <- glodapv2_2021_xover_add %>%
  rename(parameter = Parameter) %>%
  mutate(parameter = recode(parameter,
                            "alkalinity" = "talk"))


glodapv2_2021_xover_add <- glodapv2_2021_xover_add %>% 
  rename(offset = Offset,
         offset_sd = Std,
         cruise_A = Cruise_A,
         cruise_B = Cruise_B)

rm(glodapv2_2021_xover_files_add)

```

## Missing/flagged cruises

I generated this file manually based on the analysis presented in the Data loss section below.

```{r read_GLODAPv2_2021_missing_flagged_cruises}

GLODAP_cruises_missing <-
  read_csv(
    paste(
      path_glodapv2_2021,
      "GLODAPv2.2021_major_cruises_missing_flagged.csv",
      sep = ""
    )
  )

```

## IO CRM data

```{r read_IO_CRM}

CRM_IO_meas <-
  read_csv(
    paste(
      path_glodapv2_CRM,
      "/Millero_1998_Tab2.csv",
      sep = ""
    )
  )

CRM_ref_values <-
  read_csv(
    paste(
      path_glodapv2_CRM,
      "/Dickson_CRM_reference_values_20211215.csv",
      sep = ""
    )
  )

```

# Data preparation

## Correct talk qc flag

From an email conversation with Nico Lange

*Yes, we are aware of these faulty(!) calculated TA data (using DIC and fCO2). It is linked to v2.2020 where we've added fCO2 to the "missing carbon calculation matrix". Overall, including fCO2 in these calculations has worked great to fill some missing carbon gaps. However, for this cruise in particular the fCO2 values have most likely been converted wrongly to 20째C and are thus off! The problem of this all is that we haven't really done a 2nd QC on the fCO2 values neither have we defined the corresponding "G2fCO2qc" variable, hence for the sake of consistency we kept all fCO2 values in. Again and unfortunately, in this particular case it led to the bad calculations of TA data.... We plan to do a full 2nd QC on all (!) fCO2 data for v3.*

*But you have indeed found a flaw in our merging script, as the corresponding calculated TA values should not have received a 2nd QC flag of 1! I missed out on adding a line to our merging script to accommodate for the non-existence of 2nd fCO2 flags in the carbon calculation matrix.*

*So long story short: Thank you very much for finding this flaw and letting me know of it!*

and

*Yes, the all calculated TA data from cruise 695 should have a talkqc of 0 (as they are based upon un QC'd fCO2 data...).*

*And no (thanks to your hint and questions), I figured that **this wrongly assigned 2nd QC flag is a problem for all calculated carbon data, which used fCO2 for the calculations**. However, luckily this is not really often the case.*

*You can check if thats the case by looking at which other carbon parameters are measured, i.e. by **checking their primary flags (e.g. G2talkf, G2tco2f and G2phts25p0f and G2fco2f). If only two are measured and one of them is fCO2, it means that the other carbon parameters (the ones with a primary flag of 0) are calculated using fCO2. Hence, for these instances no 2nd QC is done and the corresponding qc flag should be 0 and not 1.***

```{r correct_qc_flag_of_calculated_talk_from_1_to_0}

# calculate number of measured co2 system variables

GLODAP <- GLODAP %>%
  mutate(measured_CO2_vars = rowSums(select(., c(
    tco2f, talkf, fco2f, phts25p0f
  )) == 2))

# identify cruises on which talk/tco2 was calculated

talk_qc_error_cruises <- GLODAP %>%
  select(cruise, tco2:phtsqc, measured_CO2_vars) %>% 
  filter(measured_CO2_vars == 2,
         fco2f == 2,
         talkf == 0) %>% 
  distinct(cruise, talkf, talkqc, fco2f)

tco2_qc_error_cruises <- GLODAP %>%
  select(cruise, tco2:phtsqc, measured_CO2_vars) %>% 
  filter(measured_CO2_vars == 2,
         fco2f == 2,
         tco2f == 0) %>% 
  distinct(cruise, tco2f, tco2qc, fco2f)

talk_qc_error_cruises %>% 
  write_csv("data/talk_qc_error_cruises_GLODAPv2_2021.csv")

tco2_qc_error_cruises %>% 
  write_csv("data/tco2_qc_error_cruises_GLODAPv2_2021.csv")

rm(talk_qc_error_cruises, tco2_qc_error_cruises)


# set qc = 0 for tco2 and talk values calculated from fco2   

GLODAP <- GLODAP %>%
  mutate(tco2qc = if_else(measured_CO2_vars == 2 &
                            fco2f == 2 & tco2f == 0,
                          0,
                          tco2qc))

GLODAP <- GLODAP %>%
  mutate(talkqc = if_else(measured_CO2_vars == 2 &
                            fco2f == 2 & talkf == 0,
                          0,
                          talkqc))

GLODAP <- GLODAP %>% 
  select(-measured_CO2_vars)

```

## Harmonize nomenclature

```{r harmonize_variables}

# create date column
GLODAP <- GLODAP %>%
  mutate(date = ymd(paste(year, month, day))) %>%
  relocate(date)

# harmonize column names
GLODAP <- GLODAP  %>%
  rename(sal = salinity,
         temp = temperature)

# harmonize coordinates
GLODAP <- GLODAP  %>%
  rename(lon = longitude,
         lat = latitude) %>%
  mutate(lon = if_else(lon < 20, lon + 360, lon))


```


## Horizontal gridding

For merging with other data sets, all observations were grouped into latitude intervals of:

-   1째 x 1째

```{r grid_spatially_1x1}

GLODAP <- m_grid_horizontal(GLODAP)

```


```{r check_gamma_availability, eval=FALSE}

map + 
  geom_tile(
    data = GLODAP %>% 
      filter(!is.na(gamma)) %>% 
      count(lon, lat),
    aes(lon, lat, fill = n)) +
  scale_fill_viridis_c(direction = -1)

GLODAP %>% 
  ggplot(aes(depth, gamma-sigma0)) +
  geom_hline(yintercept = 0) +
  geom_bin2d() +
  ylim(c(-1,1)) +
  scale_fill_viridis_c(trans = "log10")

```

## Apply basin mask

```{r apply_basin_mask}

# use only three basin to assign general basin mask
# ie this is not specific to the MLR fitting
basinmask_5 <- basinmask %>% 
  filter(MLR_basins == "5") %>% 
  select(lat, lon, basin)

basinmask <- basinmask %>% 
  filter(MLR_basins == "2") %>% 
  select(lat, lon, basin_AIP)

GLODAP <- inner_join(GLODAP, basinmask)

```

## Add expocodes

```{r add_expocodes}

GLODAP <- right_join(
  GLODAP_expocodes,
  GLODAP)

```

## Add row number

```{r add_row_number}

GLODAP <- GLODAP  %>%  
  mutate(row_number = row_number()) %>% 
  relocate(row_number)

```


## Split CO2 and tracers

Measurements of CO2 system and other biogeochemical parameters are separated from the measurements of halogenated tracers.

```{r split_co2_tracer}

# remove irrelevant columns
GLODAP <- GLODAP %>%
  select(-c(region,
            month:minute,
            maxsampdepth, sigma0:sigma4,
            nitrite:nitritef))


GLODAP_tracer <- GLODAP %>% 
  select(row_number:gamma,
         cfc11:sf6f,
         basin_AIP)

# select relevant columns
GLODAP <- GLODAP %>%
  select(row_number:talkqc,
         basin_AIP)


```


## Subset measured data

### tco2

The vast majority of rows is removed due to missing `tco2` observations.

```{r tco2_na_subset}

GLODAP <- GLODAP %>% 
  filter(!is.na(tco2))

```

### tracer

Rows are removed if no tracer observation is available.

```{r tracer_na_subset}

GLODAP_tracer <- GLODAP_tracer %>%
  filter(if_any(
    c(
      cfc11,
      cfc12,
      cfc113,
      ccl4,
      sf6,
      pcfc11,
      pcfc12,
      pcfc113,
      pccl4,
      psf6
    ),
    ~ !is.na(.)
  ))

```

## Create clean observations grid

### tco2

```{r create_clean_obs_grid}

GLODAP_obs_grid <- GLODAP %>% 
  count(lat, lon)

```


```{r grid_by_year, fig.asp=3}

GLODAP_grid_year <- GLODAP %>%
  count(lat, lon, year)

map +
  geom_tile(data = GLODAP_grid_year,
              aes(lon, lat)) +
  facet_wrap(~ year, ncol=3)

```

### tracer

```{r create_clean_obs_grid_tracer}

GLODAP_obs_grid_tracer <- GLODAP_tracer %>% 
  count(lat, lon)

```


```{r grid_by_year_tracer, fig.asp=3}

GLODAP_grid_year_tracer <- GLODAP_tracer %>%
  count(lat, lon, year)

map +
  geom_tile(data = GLODAP_grid_year_tracer,
              aes(lon, lat)) +
  facet_wrap(~ year, ncol=3)

```


# Flagging

In this sections, I explore the data coverage with respect to the flagging scheme. Data are not manipulated in this section.

## qc

```{r qc_flagging, fig.asp=1.5}

qc_flag <- GLODAP %>%
  mutate(decade = m_grid_decade(year),
         .after = year) %>%
  filter(!is.na(decade)) %>%
  select(lon, lat, basin_AIP, decade, cruise_expocode, ends_with("qc"))

qc_flag_grid <- qc_flag %>%
  pivot_longer(ends_with("qc"),
               names_to = "parameter",
               values_to = "value") %>%
  count(lon, lat, decade, parameter, value)

p_qc_flag_map <- qc_flag_grid %>%
  group_split(value) %>%
  # head(1) %>%
  map(
    ~ map +
      geom_tile(data = .x,
                aes(lon, lat, fill = n)) +
      facet_grid(parameter ~ decade) +
      labs(title = paste("qc flag =", unique(.x$value))) +
      scale_fill_viridis_c(
        option = "magma",
        direction = -1,
        trans = "log10"
      )
  )

p_qc_flag_map

pdf("output/qc_flag_coverage_maps.pdf")
p_qc_flag_map
dev.off()

qc_flag_grid_all_1 <- qc_flag %>%
  filter(
    if_all(ends_with("qc"), ~ . == 1)) %>%
  count(lon, lat, decade)

map +
  geom_tile(data = qc_flag_grid_all_1,
            aes(lon, lat, fill = n)) +
  facet_grid(decade ~ .) +
  labs(title = "All parameters qc == 1") +
  scale_fill_viridis_c(option = "magma",
                       direction = -1,
                       trans = "log10")

rm(qc_flag, qc_flag_grid, p_qc_flag_map, qc_flag_grid_all_1)

```

## f

```{r f_flagging, fig.asp=1.5}

f_flag <- GLODAP %>%
  mutate(decade = m_grid_decade(year),
         .after = year) %>%
  filter(!is.na(decade)) %>%
  select(lon, lat, basin_AIP, decade, cruise_expocode, ends_with("f"))

f_flag_grid <- f_flag %>%
  pivot_longer(ends_with("f"),
               names_to = "parameter",
               values_to = "value") %>%
  count(lon, lat, decade, parameter, value)

p_f_flag_map <- f_flag_grid %>% 
  group_split(value) %>%
  # head(1) %>%
  map(
    ~map +
  geom_tile(data = .x,
            aes(lon, lat, fill=n)) +
  facet_grid(parameter ~ decade) +
  labs(title = paste("f flag =", unique(.x$value))) +
    scale_fill_viridis_c(option = "magma",
                         direction = -1,
                         trans = "log10")
  )

p_f_flag_map

pdf("output/f_flag_coverage_maps.pdf")
p_f_flag_map
dev.off()

f_flag_grid_all_2 <- f_flag %>%
  filter(
    if_all(ends_with("f"), ~ . == 2)) %>%
  count(lon, lat, decade)

map +
  geom_tile(data = f_flag_grid_all_2,
            aes(lon, lat, fill = n)) +
  facet_grid(decade ~ .) +
  labs(title = "All parameters f == 2") +
  scale_fill_viridis_c(option = "magma",
                       direction = -1,
                       trans = "log10")

rm(f_flag, f_flag_grid, p_f_flag_map, f_flag_grid_all_2)

```



# Data loss

In this section, I explore the potential loss of data if certain quality quality flag criteria are not met by the observations.

```{r data_loss_prepartion}

loss_all <- GLODAP %>%
  mutate(decade = m_grid_decade(year),
         .after = year) %>%
  filter(!is.na(decade))


loss <- loss_all %>%
  filter(if_all(ends_with("f"), ~ . != 9))

map +
  geom_tile(data = loss_all %>% distinct(lon, lat, decade),
            aes(lon, lat, fill = "incl f = 9")) +
  geom_tile(data = loss %>% distinct(lon, lat, decade),
            aes(lon, lat, fill = "excl f = 9")) +
  scale_fill_brewer(palette = "Set1") +
  facet_grid(decade ~ .) +
  labs(title = "All available data") +
  theme(legend.title = element_blank())


loss_all_n <- loss_all %>%
  count(basin_AIP, decade)

loss_n <- loss %>%
  count(basin_AIP, decade)

```

## qc

Here, I analysis the loss of data due to qc flagging, based on the samples were all parameters are available (i.e. where f-flag != 9).

```{r qc_loss}

# prepare qc loss data
loss_qc <- loss %>%
  select(lon, lat, basin_AIP, decade, cruise_expocode, ends_with("qc")) %>%
  pivot_longer(ends_with("qc"),
               names_to = "parameter",
               values_to = "value") %>%
  mutate(parameter = str_remove(parameter, "qc"))

# compute fraction of qc loss per parameters and cruise
loss_qc <- loss_qc %>%
  count(cruise_expocode, basin_AIP, decade, parameter, value) %>%
  pivot_wider(
    names_from = value,
    names_prefix = "qc_",
    values_from = n,
    values_fill = 0
  ) %>%
  mutate(n_cruise = qc_0 + qc_1,
         category = if_else(qc_0 <= 0.1 * (n_cruise), "OK", "loss"))

# calculate number of parameters with loss
# separately for target/predictor variables
loss_qc_cruise <- loss_qc %>%
  mutate(parameter_class = if_else(
    parameter %in% c("tco2", "talk", "phosphate"),
    "target",
    "predictor"
  )) %>%
  count(cruise_expocode,
        basin_AIP,
        decade,
        n_cruise,
        parameter_class,
        category) %>%
  pivot_wider(names_from = category,
              values_from = n,
              values_fill = 0) %>%
  select(-OK) %>%
  pivot_wider(names_from = parameter_class,
              values_from = loss) %>%
  group_by(basin_AIP, decade) %>%
  mutate(rank_n_cruise = rank(-n_cruise)) %>%
  ungroup()

# combine with total number of observations
loss_qc_cruise <- full_join(loss_qc_cruise, loss_n)

# calculate relative contribution of cruise samples to total
loss_qc_cruise <- loss_qc_cruise %>% 
  mutate(n_cruise_rel = 100 * n_cruise / n) %>% 
  arrange(basin_AIP, decade, -n_cruise_rel) %>% 
  group_by(basin_AIP, decade) %>% 
  mutate(n_cruise_rel_cum = cumsum(n_cruise_rel)) %>% 
  ungroup() %>% 
  select(-n)

loss_qc_cruise <- loss_qc_cruise %>% 
  pivot_longer(predictor:target,
               names_to = "parameter_class",
               values_to = "loss") %>% 
  mutate(loss = as.factor(loss))

grey_plasma <- c("grey80", viridisLite::plasma(4))

# filter large cruises
loss_qc_cruise <- loss_qc_cruise %>%
  filter(n_cruise_rel >= 3)

loss_qc_cruise %>%
  group_split(basin_AIP) %>%
  # head(3) %>%
  map(
    ~ ggplot(data = .x,
             aes(rank_n_cruise, n_cruise_rel, fill = loss)) +
      geom_point(shape = 21, size = 2) +
      scale_fill_manual(values = grey_plasma,
                        name = "variables missing") +
      facet_grid(decade ~ parameter_class) +
      labs(title = paste("basin_AIP:", unique(.x$basin_AIP))) +
      ylim(0, NA)
  )



loss_qc_cruise %>%
  filter(loss != 0) %>%
  select(basin_AIP,
         decade,
         parameter_class,
         rank_n_cruise,
         cruise_expocode,
         loss) %>%
  arrange(basin_AIP, decade, parameter_class, rank_n_cruise) %>%
  kable() %>%
  kable_styling() %>%
  scroll_box(height = "300px")
  

```

```{r qc_loss_maps}

loss_grid <- loss %>% distinct(lon, lat, cruise_expocode)

loss_qc_grid <- left_join(loss_qc_cruise,
                          loss_grid)

map +
  geom_tile(data = loss_qc_grid,
            aes(lon, lat, fill = loss)) +
  facet_grid(decade ~ parameter_class) +
  scale_fill_manual(values = grey_plasma)

loss_qc_grid %>% filter(loss != 0) %>%
  group_split(parameter_class, decade) %>%
  # head(1) %>%
  map(
    ~ map +
      geom_tile(data = .x,
                aes(lon, lat, fill = cruise_expocode)) +
      scale_fill_brewer(palette = "Paired") +
      facet_grid(decade ~ parameter_class)
  )

rm(loss_qc_cruise, loss_qc_grid)

```


## f

Here, I analysis the loss of data due to f flagging, based on the samples were all parameters are available (i.e. where f-flag != 9).


```{r f_loss}

# prepare qc loss data
loss_f <- loss %>% 
  select(lon, lat, basin_AIP, decade, cruise_expocode, ends_with("f")) %>%
  pivot_longer(ends_with("f"),
               names_to = "parameter",
               values_to = "value") %>% 
  mutate(parameter = str_remove(parameter, "f"))

# compute fraction of qc loss per parameters and cruise
loss_f <- loss_f %>%
  count(cruise_expocode, basin_AIP, decade, parameter, value) %>%
  pivot_wider(
    names_from = value,
    names_prefix = "f_",
    values_from = n,
    values_fill = 0
  ) %>%
  mutate(n_cruise = f_0 + f_2,
         category = if_else(f_0 <= 0.1 * (n_cruise), "OK", "loss"))

# calculate number of parameters with loss
# separately for target/predictor variables
loss_f_cruise <- loss_f %>%
  mutate(parameter_class = if_else(
    parameter %in% c("tco2", "talk", "phosphate"),
    "target",
    "predictor"
  )) %>%
  count(cruise_expocode,
        basin_AIP,
        decade,
        n_cruise,
        parameter_class,
        category) %>% 
  pivot_wider(names_from = category,
              values_from = n,
              values_fill = 0) %>% 
  select(-OK) %>% 
  pivot_wider(names_from = parameter_class,
              values_from = loss) %>% 
  group_by(basin_AIP, decade) %>%
  mutate(rank_n_cruise = rank(-n_cruise)) %>%
  ungroup()

# combine with total number of observations
loss_f_cruise <- full_join(loss_f_cruise, loss_n)

# calculate relative contribution of cruise samples to total
loss_f_cruise <- loss_f_cruise %>% 
  mutate(n_cruise_rel = 100 * n_cruise / n) %>% 
  arrange(basin_AIP, decade, -n_cruise_rel) %>% 
  group_by(basin_AIP, decade) %>% 
  mutate(n_cruise_rel_cum = cumsum(n_cruise_rel)) %>% 
  ungroup() %>% 
  select(-n)

loss_f_cruise <- loss_f_cruise %>% 
  pivot_longer(predictor:target,
               names_to = "parameter_class",
               values_to = "loss") %>% 
  mutate(loss = as.factor(loss))

grey_plasma <- c("grey80", viridisLite::plasma(4))

# filter large cruises
loss_f_cruise <- loss_f_cruise %>%
    filter(n_cruise_rel >= 3)

loss_f_cruise %>%
  group_split(basin_AIP) %>%
  # head(1) %>%
  map(
    ~ ggplot(data = .x,
             aes(rank_n_cruise, n_cruise, fill = loss)) +
      geom_point(shape = 21, size = 2) +
      scale_fill_manual(values = grey_plasma,
                        name = "variables missing") +
      facet_grid(decade ~ parameter_class) +
      labs(title = paste("basin_AIP:", unique(.x$basin_AIP))) +
      ylim(0, NA)
  )


loss_f_cruise %>%
  filter(loss != 0) %>%
  select(basin_AIP,
         decade,
         parameter_class,
         rank_n_cruise,
         cruise_expocode,
         loss) %>%
  arrange(basin_AIP, decade, parameter_class, rank_n_cruise) %>%
  kable() %>%
  kable_styling() %>%
  scroll_box(height = "300px")
  

rm(loss_n)

```

```{r f_loss_maps}

loss_grid <- loss %>% distinct(lon, lat, cruise_expocode)

loss_f_grid <- left_join(loss_f_cruise,
                          loss_grid)
map +
  geom_tile(data = loss_f_grid,
            aes(lon, lat, fill = loss)) +
  facet_grid(decade ~ parameter_class) +
  scale_fill_manual(values = grey_plasma)

loss_f_grid %>% filter(loss != 0) %>%
  group_split(parameter_class, decade) %>%
  # head(1) %>%
  map(
    ~ map +
      geom_tile(data = .x,
                aes(lon, lat, fill = cruise_expocode)) +
      scale_fill_brewer(palette = "Paired") +
      facet_grid(decade ~ parameter_class)
  )

rm(loss_f_cruise, loss_f_grid)
rm(loss_grid)

```


## f == 9

Here, I analysis the loss of data due to unavailability (i.e. where f-flag == 9).

```{r f9_loss}

loss_f9 <- loss_all %>% 
  select(lon, lat, basin_AIP, decade, cruise_expocode, ends_with("f")) %>%
  pivot_longer(ends_with("f"),
               names_to = "parameter",
               values_to = "value") %>% 
  mutate(parameter = str_remove(parameter, "f"))

loss_f9 <- loss_f9 %>%
  count(cruise_expocode, basin_AIP, decade, parameter, value) %>%
  pivot_wider(
    names_from = value,
    names_prefix = "f_",
    values_from = n,
    values_fill = 0
  ) %>%
  mutate(n_cruise = f_0 + f_2 + f_9,
         category = if_else(f_9 <= 0.1 * (n_cruise), "OK", "loss"))

loss_f9_cruise <- loss_f9 %>%
  mutate(parameter_class = if_else(
    parameter %in% c("tco2", "talk", "phosphate"),
    "target",
    "predictor"
  )) %>%
  count(cruise_expocode,
        basin_AIP,
        decade,
        n_cruise,
        parameter_class,
        category) %>% 
  pivot_wider(names_from = category,
              values_from = n,
              values_fill = 0) %>% 
  select(-OK) %>% 
  pivot_wider(names_from = parameter_class,
              values_from = loss) %>% 
  group_by(basin_AIP, decade) %>%
  mutate(rank_n_cruise = rank(-n_cruise)) %>%
  ungroup()

loss_f9_cruise <- full_join(loss_f9_cruise, loss_all_n)

loss_f9_cruise <- loss_f9_cruise %>% 
  mutate(n_cruise_rel = 100 * n_cruise / n) %>% 
  arrange(basin_AIP, decade, -n_cruise_rel) %>% 
  group_by(basin_AIP, decade) %>% 
  mutate(n_cruise_rel_cum = cumsum(n_cruise_rel)) %>% 
  ungroup() %>% 
  select(-n)

loss_f9_cruise <- loss_f9_cruise %>% 
  pivot_longer(predictor:target,
               names_to = "parameter_class",
               values_to = "loss") %>% 
  mutate(loss = as.factor(loss))

grey_plasma <- c("grey80", viridisLite::plasma(4))

loss_f9_cruise <- loss_f9_cruise %>%
    filter(n_cruise_rel >= 3)

loss_f9_cruise %>%
  group_split(basin_AIP) %>%
  # head(1) %>%
  map(
    ~ ggplot(data = .x,
             aes(rank_n_cruise, n_cruise, fill = loss)) +
      geom_point(shape = 21, size = 2) +
      scale_fill_manual(values = grey_plasma,
                        name = "variables missing") +
      facet_grid(decade ~ parameter_class) +
      labs(title = paste("basin_AIP:", unique(.x$basin_AIP))) +
      ylim(0, NA)
  )


loss_f9_cruise %>% 
  filter(loss != 0) %>% 
  select(basin_AIP, decade, parameter_class, rank_n_cruise, cruise_expocode) %>% 
  arrange(basin_AIP, decade, parameter_class, rank_n_cruise) %>% 
  kable() %>% 
  kable_styling() %>% 
  scroll_box(height = "300px")
  

```

```{r f9_loss_maps}

loss_all_grid <- loss_all %>% distinct(lon, lat, cruise_expocode)

loss_f9_grid <- left_join(loss_f9_cruise,
                          loss_all_grid)
map +
  geom_tile(data = loss_f9_grid,
            aes(lon, lat, fill = loss)) +
  facet_grid(decade ~ parameter_class) +
  scale_fill_manual(values = grey_plasma)

loss_f9_grid %>% filter(loss != 0) %>%
  group_split(parameter_class, decade) %>%
  # head(1) %>%
  map(
    ~ map +
      geom_tile(data = .x,
                aes(lon, lat, fill = cruise_expocode)) +
      scale_fill_brewer(palette = "Paired") +
      facet_grid(decade ~ parameter_class)
  )

rm(loss_f9_cruise, loss_f9_grid)
rm(loss_all_grid)
rm(loss_all_n)
rm(loss)

```

## Relevant cruises

Below, I plot the most relevant cruises that would be lost when applying the strictest quality flagging criteria. These cruises were hand-picked, based on the relevance analysis shown above.

```{r relevant_lost_cruises}

expocodes_missing <- GLODAP_cruises_missing %>%
  distinct(cruise_expocode) %>%
  pull()

missing_cruise_grid <- loss_all %>%
  filter(cruise_expocode %in% expocodes_missing) %>% 
  distinct(cruise_expocode, decade, lon, lat)

missing_cruise_grid %>%
  group_split(decade) %>%
  # head(1) %>%
  map(
    ~ map +
      geom_tile(data = .x,
                aes(lon, lat, fill = str_sub(
                  cruise_expocode, 1, 4
                ))) +
      facet_grid(decade ~ .) +
      scale_fill_brewer(palette = "Paired",
                        name = "RV")
  )

```


## P18 phosphate

Here I analyse the phosphate data from section P18, which was repeated 3 times.

```{r P18_nitrate}

P18 <- GLODAP %>% 
  filter(cruise_expocode %in% c("33RO20161119",
                                "33RO20071215",
                                "31DS19940126"))
# plot raw data section
P18 %>% 
  filter(!is.na(nitrate)) %>% 
  ggplot(aes(lat, depth, col= nitrate)) +
  geom_point() +
  scale_color_viridis_c() +
  scale_y_reverse() +
  facet_grid(cruise_expocode ~.)

# grid section data
P18_grid <- P18 %>% 
  select(lat, lon, depth, cruise_expocode, nitrate) %>% 
  mutate(depth = as.numeric(as.character(cut(depth,
                     seq(0,1e4, 500), 
                     seq(250,1e4,500))))) %>% 
  group_by(lat, depth, cruise_expocode) %>% 
  summarise(nitrate = mean(nitrate, na.rm=TRUE)) %>% 
  ungroup()

P18_grid %>% 
  ggplot(aes(lat, depth, fill= nitrate)) +
  geom_tile() +
  scale_fill_viridis_c() +
  scale_y_reverse() +
  facet_grid(cruise_expocode ~.)

# calculate gridded offsets
P18_grid_offset <- P18_grid %>%
  pivot_wider(names_from = cruise_expocode,
              values_from = nitrate) %>%
  mutate(
    delta_nitrate_1994_2007 = (`31DS19940126` - `33RO20071215`) / `33RO20071215`,
    delta_nitrate_1994_2016 = (`31DS19940126` - `33RO20161119`) / `33RO20071215`,
    delta_nitrate_2007_2016 = (`33RO20071215` - `33RO20161119`) / `33RO20071215`
  ) %>%
  select(lat, depth, starts_with("delta")) %>%
  pivot_longer(
    starts_with("delta"),
    values_to = "delta_nitrate",
    names_to = "years",
    names_prefix = "delta_nitrate_"
  ) %>%
  filter(delta_nitrate > -20,
         depth > 1500)

P18_grid_offset %>% 
  ggplot(aes(lat, depth, fill = delta_nitrate)) +
  geom_tile() +
  scale_fill_divergent() +
  scale_y_reverse() +
  facet_grid(years ~.)

P18_grid_offset %>%
  group_by(lat, years) %>%
  summarise(delta_nitrate = mean(delta_nitrate, na.rm = TRUE)) %>%
  ungroup() %>%
  ggplot(aes(lat, delta_nitrate, col = years, fill = years)) +
  geom_hline(yintercept = 0) +
  stat_smooth(method = "lm", formula = y ~ x + I(x ^ 2)) +
  geom_point() +
  geom_line()


rm(P18, P18_grid, P18_grid_offset)

```


## A16

```{r A16}

A16 <- GLODAP %>% 
  filter(cruise_expocode %in% c(
    "33MW19930704" #A16N-1993
    ))

map + 
  geom_tile(data = A16 %>% distinct(lon, lat),
            aes(lon, lat))

A16 %>% 
  select(ends_with(c("qc"))) %>% 
  pivot_longer(everything(),
               names_to = "flag",
               values_to = "value") %>% 
  distinct(flag, value)

rm(A16)

```


# Adjustments

Typically, the reasons for multiple expocode entries of the same cruise in the adjustment table list are:

1) The cruise adjustments are different for different station, i.e. station split (e.g. 316N19821201)

-> How to merge? Based on first and last station? Cruise_ID not in GLODAP merged master file.

2) The cruise adjustments are different for different legs (e.g. 316N19871123.6) but have been merged into one cruise (316N19871123) for the product

-> How to merge? Based on first and last station?

3) The cruise adjustments have been updated/changed through the versions, here always look for the most recent entry (see table below) (e.g. 320620180309)

For the expocodes not listed in the expocode list the reason is that INDIGO has been splitted into three cruises: 35MF1985-1987 and the same holds for SAVE (316N1987 - 6legs). Further 49HH20011208 has been assigned wrongly and corrected to 49HH20011127.

Remove expocode INDIGO and maintain only 35MF19850224.
Remove expocode SAVE and maintain only 316N1987.


```{r prepare_adjustments}

GLODAP_adjustments <- GLODAP_adjustments %>%
  select(cruise_expocode,
         first_station, last_station,
         version,
         calculated_carbon_parameter,
         ends_with("_adj")) %>% 
  rename(talk_adj = alkalinity_adj)

# Remove cruises INDIGO and SAVE

GLODAP_adjustments <- 
  GLODAP_adjustments %>% 
  filter(!(cruise_expocode %in% c("INDIGO", "SAVE")))

# correct expocode 49HH20011208 to 49HH20011127

GLODAP_adjustments <- 
  GLODAP_adjustments %>% 
  mutate(cruise_expocode = if_else(
    cruise_expocode == "49HH20011208",
    "49HH20011127",
    cruise_expocode
  ))


# select latest adjustment versions
GLODAP_adjustments <- 
  GLODAP_adjustments %>% 
  group_by(cruise_expocode, first_station) %>% 
  mutate(n = n(),
         version_max = max(version)) %>%
  ungroup() %>% 
  filter(version == version_max | is.na(version)) %>% 
  select(-c(version_max, version, n))

# harmonize multiple cruise expocodes of 316N1987
GLODAP_adjustments <- GLODAP_adjustments %>% 
  mutate(cruise_expocode = str_split(cruise_expocode,
                                     "\\.",
                                     simplify = TRUE)[,1])

# correct one wrong last_cruise label
GLODAP_adjustments <- GLODAP_adjustments %>%
  mutate(
    last_station = if_else(
      cruise_expocode == "318M20091121" &
        first_station == 1,
      127,
      last_station
    )
  )

# merge with expocode table
GLODAP_adjustments <-
  full_join(GLODAP_adjustments, GLODAP_expocodes) %>%
  relocate(cruise)


GLODAP_adjustments_NA_cruises <- 
  GLODAP_adjustments %>% 
  filter(is.na(cruise))

GLODAP_adjustments_duplicated_cruises <- 
  GLODAP_adjustments %>% 
  group_by(cruise_expocode, cruise) %>% 
  mutate(n = n()) %>%
  ungroup() %>% 
  filter(n != 1)


GLODAP_adjustments %>% 
  pivot_longer(salinity_adj:c13_adj,
               names_to = "parameter",
               values_to = "adjustment") %>% 
  ggplot(aes(adjustment)) +
  geom_histogram() +
  scale_y_log10() +
  facet_wrap(~ parameter, scales = "free_x")

rm(GLODAP_adjustments_duplicated_cruises,
   GLODAP_adjustments_NA_cruises)

```


# Crossover preparation

## Histograms

```{r crossover_histograms, fig.asp=1}

GLODAP_adjustments_long <- GLODAP_adjustments %>%
  select(
    cruise_expocode,
    first_station,
    last_station,
    tco2_adj,
    talk_adj,
    phosphate_adj,
    nitrate_adj,
    oxygen_adj,
    silicate_adj,
    salinity_adj
  ) %>%
  pivot_longer(tco2_adj:salinity_adj,
               names_to = "parameter",
               values_to = "adjustment") %>% 
  mutate(parameter = str_remove(parameter, "_adj"))

p_adjustment_histo <- GLODAP_adjustments_long %>% 
  ggplot(aes(adjustment)) +
  geom_histogram() +
  scale_y_log10() +
  facet_wrap(~ parameter, scales = "free_x", ncol = 1)

p_xover_histo <- 
  ggplot() +
  geom_histogram(data = glodapv2_xover,
                 aes(offset)) +
  labs(title = "v2") +
  scale_y_log10() +
  facet_wrap(~ parameter, scales = "free_x", ncol = 1)

p_xover_histo_2021 <- 
  ggplot() +
  geom_histogram(data = glodapv2_2021_xover,
                 aes(offset)) +
  labs(title = "v2_2021") +
  scale_y_log10() +
  facet_wrap(~ parameter, scales = "free_x", ncol = 1)

p_xover_histo + p_xover_histo_2021 + p_adjustment_histo
rm(p_xover_histo, p_xover_histo_2021, p_adjustment_histo)


```

## Adjustment correction

The crossover analysis I received refer to unadjusted data. In order to analyse remaining crossover biases that are relevant for the adjusted data, the crossover results are adjusted with the same value that was also applied to the data.


```{r adjustment_correction_glodapv2}

# join crossover and adjustments
glodapv2_xover <- left_join(
  glodapv2_xover,
  GLODAP_adjustments_long %>%
    select(
      cruise_A = cruise_expocode,
      parameter,
      first_station_A = first_station,
      last_station_A = last_station,
      adjustment_A = adjustment
    )
)

glodapv2_xover <- left_join(
  glodapv2_xover,
  GLODAP_adjustments_long %>%
    select(
      cruise_B = cruise_expocode,
      parameter,
      first_station_B = first_station,
      last_station_B = last_station,
      adjustment_B = adjustment
    )
)

glodapv2_xover <- glodapv2_xover %>% 
  mutate(adjustment_A = if_else(
    parameter %in% c("salinity", "talk", "tco2"),
    replace_na(adjustment_A, 0),
    replace_na(adjustment_A, 1)
  )) %>% 
  mutate(adjustment_B = if_else(
    parameter %in% c("salinity", "talk", "tco2"),
    replace_na(adjustment_B, 0),
    replace_na(adjustment_B, 1)
  ))



# apply adjustment to crossover
glodapv2_xover <- glodapv2_xover  %>%
  mutate(offset_adj = 
           if_else(parameter %in% c("salinity", "talk", "tco2"),
                   offset + adjustment_A - adjustment_B,
                   offset * adjustment_A / adjustment_B))


```

```{r adjustment_correction_glodapv2_2021}

# join crossover and adjustments
glodapv2_2021_xover <- left_join(
  glodapv2_2021_xover,
  GLODAP_adjustments_long %>%
    select(
      cruise_A = cruise_expocode,
      parameter,
      first_station_A = first_station,
      last_station_A = last_station,
      adjustment_A = adjustment
    )
)

glodapv2_2021_xover <- left_join(
  glodapv2_2021_xover,
  GLODAP_adjustments_long %>%
    select(
      cruise_B = cruise_expocode,
      parameter,
      first_station_B = first_station,
      last_station_B = last_station,
      adjustment_B = adjustment
    )
)

glodapv2_2021_xover <- glodapv2_2021_xover %>% 
  mutate(adjustment_A = if_else(
    parameter %in% c("salinity", "talk", "tco2"),
    replace_na(adjustment_A, 0),
    replace_na(adjustment_A, 1)
  )) %>% 
  mutate(adjustment_B = if_else(
    parameter %in% c("salinity", "talk", "tco2"),
    replace_na(adjustment_B, 0),
    replace_na(adjustment_B, 1)
  ))


# apply adjustment to crossover
glodapv2_2021_xover <- glodapv2_2021_xover  %>%
  mutate(offset_adj = 
           if_else(parameter %in% c("salinity", "talk", "tco2"),
                   offset + adjustment_A,
                   offset * adjustment_A))


```

```{r join_xover_data}

xover <- bind_rows(glodapv2_xover,
                   glodapv2_2021_xover)

rm(glodapv2_xover,
   glodapv2_2021_xover)


xover <- xover %>%
  mutate(date_A = ymd(str_sub(cruise_A, 5, 12)),
         date_B = ymd(str_sub(cruise_B, 5, 12)))

# Remove cruises with expocodes starting with "OMEX"
# for which dates cannot be extracted from expocode

xover <- xover %>%
  filter(!is.na(date_A),
         !is.na(date_B))


xover <- xover %>% 
  filter(!is.na(offset_adj))

```



# Crossover analysis

### Functions

```{r define_functions_for_xover_analysis}

# reverse cruise A and B
m_xover_reverse <- function(df) {
  df_rev <- df %>%
    rename(
      cruise_A_back = cruise_A,
      cruise_A = cruise_B,
      date_A_back = date_A,
      date_A = date_B,
      n_A_back = n_A,
      n_A = n_B,
      adjustment_A_back = adjustment_A,
      adjustment_A = adjustment_B
    ) %>%
    rename(cruise_B = cruise_A_back,
           date_B = date_A_back,
           n_B = n_A_back,
           adjustment_B = adjustment_A_back) %>%
    mutate(
      offset = if_else(
        parameter %in% c("salinity", "talk", "tco2"),
        -offset,
        1 / offset
      ),
      offset_adj = if_else(
        parameter %in% c("salinity", "talk", "tco2",
                         "cstar_total", "cstar_phosphate", "cstar_talk", "cstar_tco2", "cstar_tco2_talk"),
        -offset_adj,
        1 / offset_adj
      )
    )
  return(df_rev)
}


# extract cruise based on expocode
m_xover_cruise_extractation <- function (df, expocode) {
  
  xover_cruise_A <- df %>%
    filter(cruise_A %in% expocode)
  
  xover_cruise_B <- df %>%
    filter(cruise_B %in% expocode)
  
  xover_cruise_B_rev <- m_xover_reverse(df = xover_cruise_B)
  
  xover_cruise <- bind_rows(xover_cruise_A,
                            xover_cruise_B_rev)
  
  return(xover_cruise)
}

  
```


## Missing/flagged data

Analyse crossover results for cruises that cause a relevant data gap, with the aim to inform the use of data from these cruises.

```{r crossover_missing_flagged_data}

hline_intercept <-
  tibble(parameter = unique(xover$parameter)) %>%
  mutate(intercept = if_else(parameter %in% c("salinity", "talk", "tco2"),
                             0,
                             1))

for (i_expocodes_missing in expocodes_missing) {
  # i_expocodes_missing <- expocodes_missing[1]
  
  cruise <- GLODAP %>%
    filter(cruise_expocode == i_expocodes_missing) %>% 
    rename(salinity = sal)
  
  # extract parameter that cause qc loss
  parameter_qc <- loss_qc %>%
    filter(cruise_expocode == i_expocodes_missing,
           category == "loss") 
  
  parameter_qc <- parameter_qc %>%
    pull(parameter)
  
  print(paste("qc parameter:", parameter_qc))
  
  if (length(parameter_qc) > 0) {
    parameter_qc <- parameter_qc %>% str_c(.,"qc")
  }
  
  
  # extract parameter that cause f loss
  parameter_f <- loss_f %>%
    filter(cruise_expocode == i_expocodes_missing,
           category == "loss")
  
  parameter_f <- parameter_f %>%
    pull(parameter)
  
  print(paste("f parameter:", parameter_f))
    
  if (length(parameter_f) > 0) {
    parameter_f <- parameter_f %>% str_c(.,"f")
  }
  
  # extract parameter that cause f9 loss
  parameter_f9 <- loss_f9 %>%
    filter(cruise_expocode == i_expocodes_missing,
           category == "loss")
  
  parameter_f9 <- parameter_f9 %>%
    pull(parameter)
  
  print(paste("f9 parameter:", parameter_f9))
  
  if (length(parameter_f9) > 0) {
    parameter_f9 <- parameter_f9 %>% str_c(.,"f")
  }
  
  # extract unique loss parameters
  parameter_check <-
    unique(c(parameter_qc, parameter_f, parameter_f9))
  
  rm(parameter_qc, parameter_f, parameter_f9)
  

  xover_cruise <- m_xover_cruise_extractation(
    df = xover %>% mutate(n_A = 0,
                          n_B = 0),
    expocode = i_expocodes_missing
  )

  for (i_parameter_check in parameter_check) {
    # i_parameter_check <- parameter_check[1]
    
    cruise_flag_count <- cruise %>%
      count(lon, lat, !!sym(i_parameter_check)) %>%
      group_by(lon, lat) %>%
      mutate(n_rel = 100 * n / sum(n)) %>%
      ungroup()
    
    print(
      map +
        geom_tile(data = cruise_flag_count,
                  aes(lon, lat, fill = n_rel)) +
        scale_fill_viridis_c(option = "magma",
                             direction = -1) +
        facet_wrap(i_parameter_check, ncol = 2) +
        labs(title = i_expocodes_missing,
             subtitle = i_parameter_check)
    )
    
    i_parameter_check_var <- str_remove(i_parameter_check, "f")
    i_parameter_check_var <- str_remove(i_parameter_check_var, "qc")
    
    print(
      cruise %>% 
        ggplot(aes(!!sym(i_parameter_check_var), depth, fill=station)) +
        geom_point(alpha = 0.2, shape = 21) +
        scale_fill_viridis_c() +
        scale_y_reverse() +
        facet_wrap(i_parameter_check, ncol = 2) +
        labs(title = i_expocodes_missing,
             subtitle = i_parameter_check)
    )
    
  }

  p_crossover_ts <- xover_cruise %>%
    ggplot(aes(date_B, offset_adj)) +
    geom_vline(xintercept = ymd(str_sub(i_expocodes_missing, 5)),
               col = "red") +
    geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
    geom_point() +
    facet_grid(parameter ~ ., scales = "free_y") +
    labs(title = i_expocodes_missing,
         subtitle = str_c(parameter_check, collapse = "+")) +
    theme(
      legend.position = "bottom",
      legend.direction = "vertical",
      axis.title.x = element_blank()
    )
  
  xover_cruise_decade <- xover_cruise %>%
    mutate(decade = m_grid_decade(year(date_B))) %>%
    filter(!is.na(decade)) %>%
    group_by(parameter, decade) %>%
    mutate(n = n()) %>%
    ungroup() %>% 
    filter(n > 2)
  
  
  p_crossover_decadal <-
    ggplot() +
    geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
    geom_violin(
      data = xover_cruise_decade,
      aes(x = decade, y = offset_adj),
      fill = "gold"
    ) +
    geom_boxplot(
      data = xover_cruise_decade,
      aes(x = decade, y = offset_adj),
      width = 0.2
    ) +
    labs(title = "Decadal averages") +
    facet_grid(parameter ~ ., scales = "free_y") +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_text(angle = 90))
  
  print(
  p_crossover_ts + p_crossover_decadal +
    plot_layout(widths = c(2, 1))
  )
  
  rm(p_crossover_ts, p_crossover_decadal)
  
}

rm(xover_cruise, xover_cruise_decade)

```


## IO 1990 data

```{r crossover_analysis_data, fig.asp=1.2}

IO_1990_expocodes <- GLODAP %>%
  filter(str_detect(cruise_expocode, "316N199") &
           basin_AIP == "Indian") %>%
  distinct(cruise_expocode) %>%
  pull()

xover_IO_1990 <-
  m_xover_cruise_extractation(df = xover %>% mutate(n_A = 0,
                                                    n_B = 0),
                              expocode = IO_1990_expocodes)


xover_IO_1990 <- xover_IO_1990 %>%
  mutate(RV = if_else(str_detect(cruise_B, "316N"),
                      "316N",
                      "other"))


xover_IO_1990_decade <- xover_IO_1990 %>%
    mutate(decade = m_grid_decade(year(date_B))) %>%
    filter(!is.na(decade),
           RV != "316N") %>% 
  arrange(date_B)


xover_IO_1990_decade %>%
  group_by(parameter, decade) %>%
  summarise(offset_adj_mean = mean(offset_adj, na.rm = TRUE),
            offset_adj_median = median(offset_adj, na.rm = TRUE)) %>%
  ungroup() %>%
  kable() %>%
  kable_styling() %>%
  scroll_box(height = "300px")


p_crossover_ts <- xover_IO_1990 %>%
  ggplot(aes(date_B, offset, col = RV)) +
  geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
  geom_point(shape = 21) +
  scale_color_brewer(palette = "Set1") +
  facet_grid(parameter ~ ., scales = "free_y") +
  labs(title = "Crossover 316N199XXXXX") +
  theme(
    legend.position = "bottom",
    legend.direction = "vertical",
    axis.title.x = element_blank()
  )

p_crossover_decadal <-
  ggplot() +
  geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
  geom_violin(data = xover_IO_1990_decade,
               aes(x = decade, y = offset), fill="gold") +
  geom_boxplot(data = xover_IO_1990_decade,
               aes(x = decade, y = offset),
               width = 0.2) +
  facet_grid(parameter ~ ., scales = "free_y") +
  labs(title = "Decadal offsets") +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90))


p_crossover_ts + p_crossover_decadal +
  plot_layout(widths = c(2, 1))

rm(p_crossover_ts, p_crossover_decadal)

p_crossover_ts <- xover_IO_1990 %>%
  ggplot(aes(date_B, offset_adj, col = RV)) +
  geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
  geom_point(shape = 21) +
  scale_color_brewer(palette = "Set1") +
  facet_grid(parameter ~ ., scales = "free_y") +
  labs(title = "Crossover 316N199XXXXX") +
  theme(
    legend.position = "bottom",
    legend.direction = "vertical",
    axis.title.x = element_blank()
  )

p_crossover_decadal <-
  ggplot() +
  geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
  geom_violin(data = xover_IO_1990_decade,
               aes(x = decade, y = offset_adj), fill="gold") +
  geom_boxplot(data = xover_IO_1990_decade,
               aes(x = decade, y = offset_adj),
               width = 0.2) +
  facet_grid(parameter ~ ., scales = "free_y") +
  labs(title = "Decadal offsets") +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90))

p_crossover_ts + p_crossover_decadal +
  plot_layout(widths = c(2, 1))



rm(p_crossover_ts, p_crossover_decadal)
rm(xover_IO_1990, xover_IO_1990_decade)

```


## 5 basin

In this section, I analyse GLODAP's crossover data separately for each of 5 subbasins. For this purpose, each cruise is taken into account that provided at least one measurement in the respective subbasin, irrespective of measurements done outside this subbasin.



### Cruise-by-cruise

Here, I filter all crossover and use only those were both cruises covered the basin of interest.

```{r filter_xover_basin}


# reformat basin labels
basinmask_5 <- basinmask_5 %>%
  mutate(
    basin = str_replace(basin, "_", ". "),
    basin = fct_relevel(
      basin,
      "N. Pacific",
      "S. Pacific",
      "N. Atlantic",
      "S. Atlantic",
      "Indian"
    )
  )

basins <- unique(basinmask_5$basin)
# basins <- basins[5]

GLODAP <- inner_join(GLODAP, basinmask_5)

GLODAP <- GLODAP %>%
  mutate(decade = m_grid_decade(year))

# loop over all 5 subbasins
for (i_basin in basins) {
  # i_basin <- basins[3]
  
  # retrieve subbasin expocodes
  expocodes_basin <- GLODAP %>%
    filter(basin == i_basin,
           !is.na(decade)) %>% 
    count(cruise_expocode)
  
  GLODAP_basin <- GLODAP %>% 
    filter(cruise_expocode %in% expocodes_basin$cruise_expocode)
  
  # subset cruise with all qc flag = 1
  expocodes_basin_qc <- GLODAP_basin %>%
    select(cruise_expocode, ends_with("qc")) %>%
    filter(if_all(ends_with("qc"), ~ . == 1)) %>%
    distinct(cruise_expocode) %>%
    pull(cruise_expocode)
  
  # subset cruise with all f flag = 2
  expocodes_basin_f <- GLODAP_basin %>%
    select(cruise_expocode, ends_with("f")) %>%
    filter(if_all(ends_with("f"), ~ . == 2)) %>%
    distinct(cruise_expocode) %>%
    pull(cruise_expocode)
  
  # join qc and f cruises and identify lower number of observations
  expocodes_basin <- expocodes_basin %>%
    mutate(
      parameter_coverage = if_else(
        cruise_expocode %in% expocodes_basin_qc &
          cruise_expocode %in% expocodes_basin_f,
        "full",
        "partial"
      )
    )
  
  rm(expocodes_basin_f, expocodes_basin_qc)
  
  GLODAP_basin_grid <- GLODAP_basin %>%
    count(cruise_expocode, lat, lon, decade)
  
  print(
    map +
      geom_tile(data = GLODAP_basin_grid,
                aes(lon, lat, fill = n)) +
      scale_fill_viridis_c(
        option = "magma",
        direction = -1,
        trans = "log10"
      ) +
      labs(title = i_basin) +
      facet_grid(decade ~ .) +
      theme(legend.title = element_blank())
  )
  
  GLODAP_basin_grid <- full_join(GLODAP_basin_grid %>% select(-n),
                                 expocodes_basin)
  
  print(
    map +
      geom_tile(
        data = GLODAP_basin_grid %>% filter(parameter_coverage == "partial"),
        aes(lon, lat, fill = "partial")
      ) +
      geom_tile(
        data = GLODAP_basin_grid %>% filter(parameter_coverage == "full"),
        aes(lon, lat, fill = "full")
      ) +
      scale_fill_brewer(palette = "Set1") +
      labs(title = i_basin) +
      facet_grid(decade ~ .) +
      theme(legend.title = element_blank())
  )
  
  
  # only for the N Pacifc we remove xover from cruises that go further south than 40S
  if(i_basin == "N. Pacific"){
  
  expocodes_basin_removed_40S <- GLODAP_basin_grid %>%
    filter(lat < -40) %>%
    distinct(cruise_expocode) %>%
    pull()
  
  print(
    map +
      geom_tile(
        data = GLODAP_basin_grid %>%
          filter(
            parameter_coverage == "partial" &
              cruise_expocode %in% expocodes_basin_removed_40S
          ),
        aes(lon, lat, fill = "partial")
      ) +
      geom_tile(
        data = GLODAP_basin_grid %>%
          filter(
            parameter_coverage == "full" &
              cruise_expocode %in% expocodes_basin_removed_40S
          ),
        aes(lon, lat, fill = "full")
      ) +
      scale_fill_brewer(palette = "Set1") +
      labs(title = i_basin,
           subtitle = "Removed cruises") +
      facet_grid(decade ~ .) +
      theme(legend.title = element_blank())
  )
  
  expocodes_basin <- expocodes_basin %>% 
    filter(!(cruise_expocode %in% expocodes_basin_removed_40S))
  
  print(
    map +
      geom_tile(
        data = GLODAP_basin_grid %>%
          filter(
            parameter_coverage == "partial" &
              cruise_expocode %in% expocodes_basin$cruise_expocode
          ),
        aes(lon, lat, fill = "partial")
      ) +
      geom_tile(
        data = GLODAP_basin_grid %>%
          filter(
            parameter_coverage == "full" &
              cruise_expocode %in% expocodes_basin$cruise_expocode
          ),
        aes(lon, lat, fill = "full")
      ) +
      scale_fill_brewer(palette = "Set1") +
      labs(title = i_basin,
           subtitle = "Maintained cruises") +
      facet_grid(decade ~ .) +
      theme(legend.title = element_blank())
  )
  
  }
  
  # filter crossover with both cruises falling into subbasin
  xover_basin <- xover %>%
    filter(
      cruise_A %in% expocodes_basin$cruise_expocode &
        cruise_B %in% expocodes_basin$cruise_expocode
    )

  xover_basin <- xover_basin %>%
    mutate(basin = i_basin)

  # combine with cruise meta data
  xover_basin <- left_join(
    xover_basin,
    expocodes_basin %>%
      rename(
        cruise_A = cruise_expocode,
        n_A = n,
        parameter_coverage_A = parameter_coverage
      )
  )
  
  xover_basin <- left_join(
    xover_basin,
    expocodes_basin %>%
      rename(
        cruise_B = cruise_expocode,
        n_B = n,
        parameter_coverage_B = parameter_coverage
      )
  )
  
  xover_basin <- xover_basin %>%
    mutate(
      parameter_coverage = if_else(
        parameter_coverage_A == "full" & parameter_coverage_B == "full",
        "full",
        "partial"
      ),
      n = n_A + n_B
    ) %>%
    select(-c(parameter_coverage_A, parameter_coverage_B))
  
  
  # reverse later cruise to cruise A
  xover_basin_A <- xover_basin %>%
    filter(date_A > date_B)
  
  xover_basin_B <- xover_basin %>%
    filter(date_A <= date_B)
  
  xover_basin_B_rev <- m_xover_reverse(df = xover_basin_B)
  
  
  xover_basin <- bind_rows(xover_basin_A,
                           xover_basin_B_rev)
  
  rm(xover_basin_A,
     xover_basin_B,
     xover_basin_B_rev)
  
  
  if (exists("xover_basin_all")) {
    xover_basin_all <-
      bind_rows(xover_basin_all, xover_basin)
  }
  
  if (!exists("xover_basin_all")) {
    xover_basin_all <- xover_basin
  }
  
  print(
    xover_basin %>%
      filter(
        !is.na(offset_adj),
        parameter %in% c("talk", "tco2"),
        parameter_coverage == "full"
      ) %>%
      mutate(offset_adj = cut(
        offset_adj, c(-Inf, -5, -2, -1, 1, 2, 5, Inf)
      )) %>%
      group_split(parameter) %>%
      # head(1) %>%
      map(
        ~ ggplot(data = .x,
                 aes(
                   date_A, date_B, fill = offset_adj, size = n
                 )) +
          geom_point(alpha = 0.5, shape = 21) +
          scale_fill_discrete_diverging(palette = "Blue-Red", drop = FALSE) +
          labs(title = paste(i_basin, "|", .x$parameter, "| full")) +
          coord_fixed(xlim = c(ymd("1990-01-01"), ymd("2021-01-01")),
                      ylim = c(ymd("1990-01-01"), ymd("2021-01-01")))
      )
  )
  
  print(
    xover_basin %>%
      filter(
        !is.na(offset_adj),
        parameter %in% c("phosphate"),
        parameter_coverage == "full"
      ) %>%
      mutate(offset_adj = cut(
        offset_adj, 1 + c(-Inf, -5, -2, -1, 1, 2, 5, Inf) /
          100
      )) %>%
      group_split(parameter) %>%
      # head(1) %>%
      map(
        ~ ggplot(data = .x,
                 aes(
                   date_A, date_B, fill = offset_adj, size = n
                 )) +
          geom_point(alpha = 0.5, shape = 21) +
          scale_fill_discrete_diverging(palette = "Blue-Red", drop = FALSE) +
          labs(title = paste(i_basin, "|", .x$parameter, "| full")) +
          coord_fixed(xlim = c(ymd("1990-01-01"), ymd("2021-01-01")),
                      ylim = c(ymd("1990-01-01"), ymd("2021-01-01")))
      )
  )
  
  print(
    xover_basin %>%
      filter(!is.na(offset_adj),
             parameter %in% c("talk", "tco2")) %>%
      mutate(offset_adj = cut(
        offset_adj, c(-Inf, -5, -2, -1, 1, 2, 5, Inf)
      )) %>%
      group_split(parameter) %>%
      # head(1) %>%
      map(
        ~ ggplot(data = .x,
                 aes(
                   date_A, date_B, fill = offset_adj, size = n
                 )) +
          geom_point(alpha = 0.5, shape = 21) +
          scale_fill_discrete_diverging(palette = "Blue-Red", drop = FALSE) +
          labs(title = paste(i_basin, "|", .x$parameter, "| partial")) +
          coord_fixed(xlim = c(ymd("1990-01-01"), ymd("2021-01-01")),
                      ylim = c(ymd("1990-01-01"), ymd("2021-01-01")))
      )
  )
  
  print(
    xover_basin %>%
      filter(!is.na(offset_adj),
             parameter %in% c("phosphate")) %>%
      mutate(offset_adj = cut(
        offset_adj, 1 + c(-Inf, -5, -2, -1, 1, 2, 5, Inf) /
          100
      )) %>%
      group_split(basin, parameter) %>%
      # head(1) %>%
      map(
        ~ ggplot(data = .x,
                 aes(
                   date_A, date_B, fill = offset_adj, size = n
                 )) +
          geom_point(alpha = 0.5, shape = 21) +
          scale_fill_discrete_diverging(palette = "Blue-Red", drop = FALSE) +
          labs(title = paste(i_basin, "|", .x$parameter, "| partial")) +
          coord_fixed(xlim = c(ymd("1990-01-01"), ymd("2021-01-01")),
                      ylim = c(ymd("1990-01-01"), ymd("2021-01-01")))
      )
  )
  
}


rm(xover_basin, GLODAP_basin, GLODAP_basin_grid, expocodes_basin)

xover_basin <- xover_basin_all
rm(xover_basin_all)

```

### Cruise-by-cruise C*


```{r convert_offset_to_cstar_units}

xover_basin <- xover_basin %>% 
    group_by(basin,
             cruise_A,
             cruise_B,
             date_A,
             date_B,
             n_A,
             n_B,
             n,
             parameter,
             parameter_coverage) %>%
    summarise(
      offset_adj = mean(offset_adj, na.rm = TRUE)
    ) %>%
    ungroup()



xover_basin <- xover_basin %>% 
  filter(parameter %in% c("tco2", "talk", "phosphate")) %>% 
  pivot_wider(names_from = parameter,
              values_from = offset_adj)

GLODAP_deep_phosphate <- GLODAP %>% 
  filter(depth > 1500) %>% 
  group_by(basin) %>% 
  summarise(phosphate_mean = mean(phosphate, na.rm = TRUE)) %>% 
  ungroup()

xover_basin <- full_join(xover_basin,
                               GLODAP_deep_phosphate)

rm(GLODAP_deep_phosphate)

xover_basin <- xover_basin %>%
  mutate(
    cstar_tco2 = tco2,
    cstar_talk = -0.5 * talk,
    phosphate_fac = phosphate - 1,
    cstar_phosphate = -117 * phosphate_fac * phosphate_mean - 16 * 0.5 * phosphate_fac * phosphate_mean
  ) %>% 
  select(-phosphate_fac)


xover_basin %>%
  select(starts_with("cstar")) %>% 
  pivot_longer(starts_with("cstar"),
              names_to = "parameter",
              values_to = "value") %>% 
  ggplot(aes(value)) +
  geom_histogram() +
  facet_wrap(~parameter, scales = "free_x")

xover_basin <- xover_basin %>% 
  select(-c(phosphate_mean, tco2, talk))

xover_basin <- xover_basin %>% 
  mutate(cstar_total = cstar_tco2 + cstar_talk + cstar_phosphate,
         cstar_tco2_talk = cstar_tco2 + cstar_talk) %>% 
  pivot_longer(phosphate:cstar_tco2_talk,
               names_to = "parameter",
               values_to = "offset_adj")

xover_basin <- xover_basin %>% 
  drop_na()


```


```{r cruise_by_cruise_cstar}

xover_basin %>%
  filter(parameter_coverage == "full") %>% 
  # filter(basin == "N. Pacific") %>% 
  mutate(offset_adj = cut(offset_adj, c(-Inf, -5, -2, -1, 1, 2, 5, Inf))) %>%
  group_split(basin, parameter) %>%
  # head(1) %>%
  map(
    ~ ggplot(data = .x,
             aes(
               date_A, date_B, fill = offset_adj, size = n
             )) +
      geom_point(alpha = 0.5, shape = 21) +
      scale_fill_discrete_diverging(palette = "Blue-Red", drop = FALSE) +
      labs(title = paste(.x$basin, "|", .x$parameter, "| full")) +
      coord_fixed(xlim = c(ymd("1990-01-01"), ymd("2021-01-01")),
                  ylim = c(ymd("1990-01-01"), ymd("2021-01-01")))
  )

xover_basin %>%
  mutate(offset_adj = cut(offset_adj, c(-Inf, -5, -2, -1, 1, 2, 5, Inf))) %>%
  # filter(basin == "N. Pacific") %>% 
  group_split(basin, parameter) %>%
  # head(1) %>%
  map(
    ~ ggplot(data = .x,
             aes(
               date_A, date_B, fill = offset_adj, size = n
             )) +
      geom_point(alpha = 0.5, shape = 21) +
      scale_fill_discrete_diverging(palette = "Blue-Red", drop = FALSE) +
      labs(title = paste(.x$basin, "|", .x$parameter, "| partial")) +
      coord_fixed(xlim = c(ymd("1990-01-01"), ymd("2021-01-01")),
                  ylim = c(ymd("1990-01-01"), ymd("2021-01-01")))
  )

xover_basin %>%
  mutate(offset_adj = cut(offset_adj, c(-Inf, -5, -2, -1, 1, 2, 5, Inf))) %>%
  filter(parameter_coverage == "full") %>%
  ggplot(aes(date_A, date_B, fill = offset_adj, size = n)) +
  geom_point(alpha = 0.5, shape = 21) +
  scale_fill_discrete_diverging(palette = "Blue-Red", drop = FALSE) +
  coord_fixed(xlim = c(ymd("1990-01-01"), ymd("2021-01-01")),
              ylim = c(ymd("1990-01-01"), ymd("2021-01-01"))) +
  facet_grid(basin ~ parameter)


```

### Cruise-by-cruise annual mean

```{r cruise_by_cruise_cstar_annual_mean}

xover_basin_annual <- xover_basin %>% 
  filter(parameter_coverage == "full") %>% 
  mutate(date_A = year(date_A),
         date_B = year(date_B)) %>% 
  group_by(date_A, date_B, parameter, basin) %>% 
  summarise(offset_adj_weighted_mean = weighted.mean(offset_adj, w = n),
            n = mean(n)) %>% 
  ungroup()

xover_basin_annual %>%
  mutate(offset_adj_weighted_mean = cut(offset_adj_weighted_mean, c(-Inf, -5, -2, -1, 1, 2, 5, Inf))) %>%
  group_split(basin, parameter) %>%
  # head(1) %>%
  map(
    ~ ggplot(data = .x,
             aes(
               date_A, date_B, fill = offset_adj_weighted_mean, size = n)) +
      geom_point(shape = 21) +
      scale_fill_discrete_diverging(palette = "Blue-Red", drop = FALSE) +
      labs(title = paste(.x$basin, "|", .x$parameter, "| full")) +
      coord_fixed(xlim = c(1990,2021),
                  ylim = c(1990,2021))
  )


```


### Cruise mean offsets

The aim of the decadal scale analysis is to investigate mean crossover offsets between all cruises from two decades. 

```{r crossover_analysis_5_basin_decadal, fig.asp=1.5, results='asis'}

expocodes_basin <- unique(c(xover_basin$cruise_A, xover_basin$cruise_B)) 


# loop over each cruises
# determine the mean decadal crossover from other cruises
for (i_cruise_expocode in expocodes_basin) {
  # i_cruise_expocode <- expocodes_basin[1]

  xover_cruise <- m_xover_cruise_extractation(
    df = xover_basin %>% mutate(adjustment_A = 0,
                                adjustment_B = 0,
                                offset = 0),
    expocode = i_cruise_expocode)
  
  xover_cruise <- xover_cruise %>% 
    select(-c(starts_with("adjustment"), offset))

  # calculate long-term mean offsets for cruise
  # Note: weighting is only done based on size of cruise B
  xover_cruise_partial <- xover_cruise %>%
    group_by(cruise_A, date_A, n_A, parameter, basin) %>%
    summarise(
      offset_adj_mean = mean(offset_adj, na.rm = TRUE),
      offset_adj_mean_weighted = weighted.mean(x = offset_adj, w = n_B, na.rm = TRUE)
    ) %>%
    ungroup()
  
  xover_cruise_full <- xover_cruise %>%
    filter(parameter_coverage == "full") %>%
    group_by(cruise_A, date_A, n_A, parameter, basin) %>%
    summarise(
      offset_adj_mean = mean(offset_adj, na.rm = TRUE),
      offset_adj_mean_weighted = weighted.mean(x = offset_adj, w = n_B, na.rm = TRUE)
    ) %>%
    ungroup()
  
  xover_cruise_long_term <- bind_rows(
    xover_cruise_full %>% mutate(parameter_coverage = "full"),
    xover_cruise_partial %>% mutate(parameter_coverage = "partial")
  )
  
  
  rm(xover_cruise_full,
     xover_cruise_partial)
  
  if (exists("xover_cruise_long_term_all")) {
    xover_cruise_long_term_all <-
      bind_rows(xover_cruise_long_term_all, xover_cruise_long_term)
  }
  
  if (!exists("xover_cruise_long_term_all")) {
    xover_cruise_long_term_all <- xover_cruise_long_term
  }
  
  
  # cut cruise B date into decades
  xover_cruise <- xover_cruise %>%
    mutate(decade = m_grid_decade(year(date_B))) %>%
    arrange(date_B)
  
  # calculate decadal mean offsets for cruise
  # Note: weighting is only done based on size of cruise B
  xover_cruise_decade_partial <- xover_cruise %>%
    group_by(cruise_A, date_A, n_A, parameter, decade, basin) %>%
    summarise(
      # offset_adj_sd = sd(offset_adj, na.rm = TRUE),
      offset_adj_mean = mean(offset_adj, na.rm = TRUE),
      offset_adj_mean_weighted = weighted.mean(x = offset_adj, w = n_B, na.rm = TRUE)
    ) %>%
    ungroup()
  
  xover_cruise_decade_full <- xover_cruise %>%
    filter(parameter_coverage == "full") %>%
    group_by(cruise_A, date_A, n_A, parameter, decade, basin) %>%
    summarise(
      # offset_adj_sd = sd(offset_adj, na.rm = TRUE),
      offset_adj_mean = mean(offset_adj, na.rm = TRUE),
      offset_adj_mean_weighted = weighted.mean(x = offset_adj, w = n_B, na.rm = TRUE)
    ) %>%
    ungroup()
  
  xover_cruise_decade <- bind_rows(
    xover_cruise_decade_full %>% mutate(parameter_coverage = "full"),
    xover_cruise_decade_partial %>% mutate(parameter_coverage = "partial")
  )
  
  
  rm(xover_cruise_decade_full,
     xover_cruise_decade_partial)
  
  if (exists("xover_cruise_decade_all")) {
    xover_cruise_decade_all <-
      bind_rows(xover_cruise_decade_all, xover_cruise_decade)
  }
  
  if (!exists("xover_cruise_decade_all")) {
    xover_cruise_decade_all <- xover_cruise_decade
  }
  
}


hline_intercept <-
  tibble(parameter = unique(xover_basin$parameter)) %>%
  mutate(intercept = if_else(parameter %in% c("phosphate"),
                             1,
                             0))

xover_cruise_long_term_all %>%
  filter(parameter_coverage == "full") %>% 
  group_split(basin) %>%
  # head(1) %>%
  map(
    ~ ggplot(data = .x,
             aes(date_A, offset_adj_mean_weighted, size = n_A)) +
        geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
      geom_point(alpha = 0.3) +
      labs(title = paste(.x$basin, "| full")) +
      # coord_cartesian(ylim = c(-10,10)) +
      facet_grid(parameter ~ ., scales = "free_y")
  )

xover_cruise_decade_all %>%
  filter(parameter_coverage == "full") %>% 
  group_split(basin) %>%
  # head(1) %>%
  map(
    ~ ggplot(data = .x,
             aes(date_A, offset_adj_mean_weighted, size = n_A)) +
        geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
      geom_point(alpha = 0.3) +
      labs(title = paste(.x$basin, "| full")) +
      # coord_cartesian(ylim = c(-10,10)) +
      facet_grid(parameter ~ decade, scales = "free_y")
  )


```

```{r xover_cruise_mean_by_cruise_size, fig.asp=1.5}

xover_cruise_long_term_all <- xover_cruise_long_term_all %>%
  mutate(decade_A = m_grid_decade(year(date_A)))

xover_cruise_long_term_all %>%
  filter(parameter_coverage == "full") %>% 
  group_split(basin) %>%
  # head(1) %>%
  map(
    ~ ggplot(data = .x,
             aes(n_A, offset_adj_mean_weighted, size = n_A, fill = decade_A)) +
        geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
      geom_point(alpha = 0.5, shape = 21) +
      scale_fill_discrete_sequential(palette = "viridis") +
      labs(title = paste(.x$basin, "| full")) +
      # coord_cartesian(ylim = c(-10,10)) +
      facet_grid(parameter ~ ., scales = "free_y")
  )

xover_cruise_decade_all <- xover_cruise_decade_all %>%
  mutate(decade_A = m_grid_decade(year(date_A))) 

xover_cruise_decade_all %>%
  filter(parameter_coverage == "full") %>% 
  group_split(basin) %>%
  # head(1) %>%
  map(
    ~ ggplot(data = .x,
             aes(n_A, offset_adj_mean_weighted, size = n_A, fill = decade_A)) +
        geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
      geom_point(alpha = 0.5, shape = 21) +
      scale_fill_discrete_sequential(palette = "viridis") +
      labs(title = paste(.x$basin, "| full")) +
      # coord_cartesian(ylim = c(-10,10)) +
      facet_grid(parameter ~ decade, scales = "free_y")
  )


```

#### PO

```{r xover_cruise_mean_by_cruise_size_PO, fig.asp=1.5}

xover_cruise_decade_all %>%
  filter(
    parameter_coverage == "full",
    basin == "N. Pacific",
    decade != unique(xover_cruise_decade_all$decade)[1]
  ) %>%
  group_split(basin) %>%
  # head(1) %>%
  map(
    ~ ggplot(
      data = .x,
      aes(
        n_A,
        offset_adj_mean_weighted,
        size = n_A,
        fill = decade_A
      )
    ) +
      geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
      geom_point(alpha = 0.5, shape = 21) +
      scale_fill_discrete_sequential(palette = "viridis") +
      labs(title = paste(.x$basin, "| full")) +
      # coord_cartesian(ylim = c(-10,10)) +
      facet_grid(parameter ~ decade, scales = "free_y")
  )

```



### Decadal averages

```{r xover_decadal_averages, fig.asp=1.5}

xover_cruise_long_term_all %>%
  filter(parameter_coverage == "full") %>%
  group_split(basin) %>%
  # head(1) %>%
  map(
    ~ ggplot(data = .x,
             aes(decade_A, offset_adj_mean_weighted)) +
        geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
      geom_boxplot() +
      geom_point(aes(size = n_A), alpha = 0.3) +
      scale_fill_discrete_sequential(palette = "viridis") +
      labs(title = paste(.x$basin, "| full")) +
      # coord_cartesian(ylim = c(-10,10)) +
      facet_grid(parameter ~ ., scales = "free_y")
  )

xover_cruise_long_term_all %>%
  group_by(basin, decade_A, parameter_coverage, parameter) %>%
  summarise(
    offset_adj_sd = sd(offset_adj_mean_weighted, na.rm = TRUE),
    offset_adj_mean_weighted = weighted.mean(offset_adj_mean_weighted, w = n_A)
  ) %>%
  ungroup() %>%
  drop_na() %>%
  filter(parameter_coverage == "full") %>%
  ggplot(
    aes(
      decade_A,
      offset_adj_mean_weighted,
      ymin = offset_adj_mean_weighted - offset_adj_sd,
      ymax = offset_adj_mean_weighted + offset_adj_sd
    )
  ) +
    geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
  geom_linerange() +
  geom_point() +
  facet_grid(parameter ~ basin, scales = "free_y") +
  # coord_cartesian(ylim = c(-10,10)) +
  theme(axis.text.x = element_text(angle = 90))


xover_cruise_decade_all %>%
  filter(parameter_coverage == "full") %>%
  group_split(basin) %>%
  # head(1) %>%
  map(
    ~ ggplot(
      data = .x,
      aes(
        decade_A,
        offset_adj_mean_weighted
      )
    ) +
        geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
      geom_boxplot() +
      geom_point(aes(size = n_A), alpha = 0.3) +
      scale_fill_discrete_sequential(palette = "viridis") +
      labs(title = paste(.x$basin, "| full")) +
      # coord_cartesian(ylim = c(-10,10)) +
      facet_grid(parameter ~ decade, scales = "free_y")
  )


xover_cruise_decade_all_stats <- xover_cruise_decade_all %>%
  group_by(basin, decade_A, decade, parameter_coverage, parameter) %>%
  summarise(
    offset_adj_sd = sd(offset_adj_mean_weighted),
    offset_adj_mean_weighted = weighted.mean(offset_adj_mean_weighted, w = n_A)
  ) %>%
  ungroup() %>%
  drop_na() %>%
  filter(parameter_coverage == "full")

xover_cruise_decade_all_stats %>%
  group_split(basin) %>%
  # head(1) %>%
  map(
    ~ ggplot(
      data = .x,
      aes(
        decade_A,
        offset_adj_mean_weighted,
        ymin = offset_adj_mean_weighted - offset_adj_sd,
        ymax = offset_adj_mean_weighted + offset_adj_sd
      )
    ) +
      geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
      geom_linerange() +
      geom_point() +
      labs(title = .x$basin) +
      facet_grid(parameter ~ decade, scales = "free_y") +
      # coord_cartesian(ylim = c(-10,10)) +
      theme(axis.text.x = element_text(angle = 90))
  )

xover_cruise_decade_all_stats %>% 
  kable() %>%
  kable_styling() %>%
  scroll_box(height = "300px")

```



# RV activity

```{r RV_activity}

GLODAP_counts <- GLODAP %>%
  mutate(decade = m_grid_decade(year),
         .after = year) %>% 
  filter(!is.na(decade))

GLODAP_counts <- GLODAP_counts %>% 
  mutate(RV = str_sub(cruise_expocode, 1, 4))

RV_activity <- GLODAP_counts %>% 
  count(decade, basin_AIP, RV) %>% 
  group_by(decade, basin_AIP) %>% 
  mutate(n_total = sum(n)) %>% 
  ungroup() %>% 
  mutate(n_prop = 100* n / n_total)

RV_activity <-RV_activity %>% 
  group_by(decade, basin_AIP) %>% 
  mutate(rank = rank(-n_prop)) %>% 
  ungroup()

RV_activity %>% 
  ggplot(aes(rank, n_prop)) +
  geom_line() +
  geom_point() +
  geom_text(data = RV_activity %>% filter(n_prop > 20),
             aes(rank, n_prop, label = RV),
             nudge_x = 5) +
  labs(y = "proportion of tco2 samples (%)") +
  facet_grid(decade ~ basin_AIP)

rm(RV_activity)

```



# Largest cruises

```{r large_cruises, fig.asp=0.5}

large_cruises <- GLODAP_counts %>% 
  count(decade, basin_AIP, cruise_expocode) %>% 
  group_by(decade, basin_AIP) %>% 
  mutate(n_total = sum(n)) %>% 
  ungroup() %>% 
  mutate(n_prop = 100* n / n_total)

large_cruises <- large_cruises %>% 
  group_by(decade, basin_AIP) %>% 
  mutate(rank = rank(-n_prop)) %>% 
  ungroup()


large_cruises %>%
  group_split(decade, basin_AIP) %>%
  head(1) %>%
  map(
    ~
      ggplot(data = .x,
             aes(rank, n_prop)) +
      geom_line() +
      geom_point(
        data = .x %>% filter(rank <= 5),
        aes(rank, n_prop, fill = cruise_expocode), shape = 21) +
      scale_fill_brewer(palette = "Set1") +
      xlim(0, max(large_cruises$rank)) +
      labs(y = "proportion of tco2 samples (%)") +
      facet_grid(decade ~ basin_AIP)
  )

large_cruises %>%
  filter(rank <= 5) %>% 
  select(decade, basin_AIP, rank, n_prop, cruise_expocode) %>% 
  mutate(n_prop = round(n_prop, 1)) %>% 
  arrange(decade, basin_AIP, rank) %>% 
  kable() %>% 
  kable_styling() %>% 
  scroll_box(height = "300px")

rm(GLODAP_count, large_cruises)

```



# Indian Ocean 1990 CRM

```{r IO_1990_CRM}

CRM_IO_meas <- CRM_IO_meas %>%
  fill(cruise:batch) %>% 
  select(-starts_with("ph")) %>% 
  rename(talk_meas = talk_ave,
         tco2_meas = tco2_ave)
  
CRM_ref_values <- CRM_ref_values %>% 
  select(-c(date, comment, sal)) %>% 
  rename(talk_ref = talk,
         tco2_ref = tco2)

IO_CRM_offset <-
  left_join(CRM_IO_meas,
            CRM_ref_values) %>% 
  mutate(batch = as.factor(batch))

IO_CRM_offset <- IO_CRM_offset %>% 
  mutate(talk_offset = talk_meas - talk_ref,
         tco2_offset = tco2_meas - tco2_ref)

IO_CRM_offset <- IO_CRM_offset %>% 
  select(-c(talk_meas:talk_ref)) %>% 
  pivot_longer(ends_with("_offset"),
               values_to = "offset",
               names_to = "parameter") %>% 
  mutate(parameter = str_remove(parameter, "_offset"),
         start_date = mdy(start_date))

IO_CRM_offset %>% 
  ggplot(aes(offset)) +
  geom_histogram(binwidth = 1) +
  facet_wrap(~ parameter)

IO_CRM_offset <- IO_CRM_offset %>% 
  filter(cell != "All")

IO_CRM_offset_mean <- IO_CRM_offset %>% 
  group_by(parameter) %>% 
  summarise(offset_mean = mean(offset),
            offset_sd = sd(offset)) %>% 
  ungroup()

IO_CRM_offset %>%
  filter(parameter == "talk") %>%
  ggplot() +
  scale_fill_brewer(palette = "Set1",
                    name = "CRM batch") +
  geom_hline(data = IO_CRM_offset_mean %>% filter(parameter == "talk"),
             aes(yintercept = offset_mean)) +
  geom_hline(
    data = IO_CRM_offset_mean %>% filter(parameter == "talk"),
    aes(yintercept = offset_mean - offset_sd),
    linetype = 2
  ) +
  geom_hline(
    data = IO_CRM_offset_mean %>% filter(parameter == "talk"),
    aes(yintercept = offset_mean + offset_sd),
    linetype = 2
  ) +
  geom_point(aes(start_date, offset, fill = batch, size=n),
             shape = 21) +
  scale_size(name = "Nr of\nmeasurements") +
  labs(x = "Cruise start date",
       y = "TA offset meas-CRM (쨉mol/kg)",
       title = "RV Knorr IO 1990 - TA reference measurements",
       subtitle = "Data source: Tables 1 and 2 from Millero et al. (1998)")


```


# Write files

```{r write_clean_data_files}

GLODAP  %>%
  select(-cruise_expocode) %>% 
  write_csv(paste(path_preprocessing,
                  "GLODAPv2.2021_preprocessed.csv",
                  sep = ""))

GLODAP_tracer  %>%
  write_csv(paste(
    path_preprocessing,
    "GLODAPv2.2021_preprocessed_tracer.csv",
    sep = ""
  ))

GLODAP_adjustments  %>%
  write_csv(paste(path_preprocessing,
                  "GLODAPv2.2021_adustments.csv",
                  sep = ""))

# GLODAP_adjustments_NA_cruises  %>%
#   select(cruise_expocode, cruise) %>%
#   write_csv(paste(
#     path_preprocessing,
#     "GLODAPv2.2021_adustments_NA_cruises.csv",
#     sep = ""
#   ))
# 
# GLODAP_adjustments_duplicated_cruises  %>%
#   drop_na() %>%
#   write_csv(
#     paste(
#       path_preprocessing,
#       "GLODAPv2.2021_adustments_duplicated_cruises.csv",
#       sep = ""
#     )
#   )

```

# Overview plots

## Assign coarse spatial grid

For the following plots, the cleaned data set was re-opened and observations were gridded spatially to intervals of:

-   5째 x 5째

```{r grid_spatially_5x5}

GLODAP <- m_grid_horizontal_coarse(GLODAP)

```

## Histogram Zonal coverage

```{r coverage_histogram_zonal}

GLODAP_histogram_lat <- GLODAP %>%
  group_by(lat_grid) %>%
  tally() %>%
  ungroup()

GLODAP_histogram_lat %>%
  ggplot(aes(lat_grid, n)) +
  geom_col() +
  coord_flip() +
  theme(legend.title = element_blank())

rm(GLODAP_histogram_lat)

```

## Histogram temporal coverage

```{r coverage_histogram_temporal}

GLODAP_histogram_year <- GLODAP %>%
  group_by(year) %>%
  tally() %>%
  ungroup()

GLODAP_histogram_year %>%
  ggplot() +
  geom_col(aes(year, n)) +
  theme(
    axis.title.x = element_blank()
  )

rm(GLODAP_histogram_year)

```

## Zonal temporal coverage (Hovmoeller)

```{r coverage_hovmoeller}

GLODAP_hovmoeller_year <- GLODAP %>%
  group_by(year, lat_grid) %>%
  tally() %>%
  ungroup()

GLODAP_hovmoeller_year %>%
  ggplot(aes(year, lat_grid, fill = log10(n))) +
  geom_tile() +
  geom_vline(xintercept = c(1999.5, 2012.5)) +
  scale_fill_viridis_c(option = "magma", direction = -1) +
  theme(legend.position = "top",
        axis.title.x = element_blank())

rm(GLODAP_hovmoeller_year)

```

## Coverage map

```{r coverage_map, fig.asp=0.5}

map +
  geom_raster(data = GLODAP_obs_grid,
              aes(lon, lat, fill = log10(n))) +
  scale_fill_viridis_c(option = "magma",
                       direction = -1)

```

```{r coverage_map_variable_year, message=FALSE, results='hide'}

GLODAP_obs_grid_all_vars <- GLODAP %>% 
  select(year, lat, lon, cruise, sal, temp, oxygen,
         phosphate, nitrate, silicate, tco2, talk) %>% 
  pivot_longer(cols = sal:talk,
               names_to = "parameter",
               values_to = "value") %>% 
  mutate(presence = if_else(is.na(value), "missing", "available")) %>% 
  count(year, lat, lon, parameter, presence)

GLODAP_obs_grid_all_vars_wide <- GLODAP_obs_grid_all_vars %>% 
  pivot_wider(names_from = "presence",
              values_from = n,
              values_fill = 0) %>% 
  mutate(ratio_available = available/(available+missing))

all_plots <- GLODAP_obs_grid_all_vars_wide %>%
  # mutate(cruise = as.factor(cruise)) %>%
  group_split(year) %>%
  # tail(3) %>%
  map(
    ~ map +
      geom_tile(
        data = .x,
        aes(
          x = lon,
          y = lat,
          width = 1,
          height = 1,
          fill = ratio_available
        )
      ) +
      scale_fill_scico(palette = "berlin",
                       limits = c(0,1)) +
      labs(title = unique(.x$year)) +
      facet_wrap(~ parameter)
  )


pdf(file = paste0(path_preprocessing, "GLODAPv2.2021_preprocessed_coverage_maps.pdf"),
    width = 10, 
    height = 5)
all_plots
dev.off()

```


# CANYON-B

## Prediction

```{r calc_CANYON-B}

source("/net/kryo/work/uptools/co2_calculation/CANYON-B/CANYONB.R")

GLODAP_CB <- GLODAP %>%
  mutate(lon = if_else(lon > 180, lon - 360, lon)) %>%
  arrange(year) %>% 
  select(row_number, year, date, lat, lon, depth, basin_AIP,
         temp, sal, oxygen,
         talk, tco2, nitrate, phosphate, silicate)

# filter rows with essential variables for Canyon-B
GLODAP_CB <- GLODAP_CB %>%
  filter(across(c(lat, lon, depth,
                  temp, sal, oxygen), ~ !is.na(.x)))

GLODAP_CB <- GLODAP_CB %>%
  mutate(as_tibble(
    CANYONB(
      date = paste0(as.character(date), " 12:00"),
      lat = lat,
      lon = lon,
      pres = depth,
      temp = temp,
      psal = sal,
      doxy = oxygen,
      param = c("AT", "CT", "NO3", "PO4", "SiOH4")
    )
  ))

GLODAP_CB <- GLODAP_CB %>%
  select(-ends_with(c("_cim", "_cin", "_cii")))


GLODAP_CB <- GLODAP_CB %>%
  rename(
    "talk_CANYONB" = "AT",
    "tco2_CANYONB" = "CT",
    "nitrate_CANYONB" = "NO3",
    "phosphate_CANYONB" = "PO4",
    "silicate_CANYONB" = "SiOH4"
  )



```

## Comparison to observations

```{r CANYON-B_vs_observationd, fig.asp=0.4}


variables <- c("talk", "tco2", "nitrate", "phosphate", "silicate")

for (i_variable in variables) {
  # i_variable <- variables[1]
  
  # calculate equal axis limits and binwidth
  axis_lims <- GLODAP_CB %>%
    drop_na() %>% 
    summarise(max_value = max(c(max(
      !!sym(i_variable)
    ),
    max(!!sym(
      paste0(i_variable, "_CANYONB")
    )))),
    min_value = min(c(min(
      !!sym(i_variable)
    ),
    min(!!sym(
      paste0(i_variable, "_CANYONB")
    )))))
  
  binwidth_value <- (axis_lims$max_value - axis_lims$min_value) / 60
  axis_lims <- c(axis_lims$min_value, axis_lims$max_value)
  
  print(
    ggplot(GLODAP_CB, aes(
      x = !!sym(i_variable),
      y = !!sym(paste0(i_variable, "_CANYONB"))
    )) +
      geom_bin2d(binwidth = binwidth_value) +
      scale_fill_viridis_c(trans = "log10") +
      geom_abline(slope = 1, col = 'red') +
      coord_equal(xlim = axis_lims,
                  ylim = axis_lims) +
      facet_wrap( ~ basin_AIP) +
      labs(title = "All years")
  ) 
  
  
  # for (i_year in unique(GLODAP_CB$year)) {
  #   # i_year <- 2017
  #   
  #   print(
  #     ggplot(
  #       GLODAP_CB %>% filter(year == i_year),
  #       aes(x = !!sym(i_variable),
  #           y = !!sym(paste0(
  #             i_variable, "_CANYONB"
  #           )))
  #     ) +
  #       geom_bin2d(binwidth = binwidth_value) +
  #       scale_fill_viridis_c(trans = "log10") +
  #       geom_abline(slope = 1, col = 'red') +
  #       coord_equal(xlim = axis_lims,
  #                   ylim = axis_lims) +
  #       facet_wrap( ~ basin_AIP) +
  #       labs(title = paste("Year:", i_year))
  #   )
  # }
  
}



```

## Write files

```{r write_Canyon-B_data_file}

GLODAP_CB %>% 
  select(row_number,
         talk_CANYONB, tco2_CANYONB,
         nitrate_CANYONB, phosphate_CANYONB, silicate_CANYONB) %>% 
  write_csv(paste(path_preprocessing,
                             "GLODAPv2.2021_Canyon-B.csv",
                             sep = ""))

```

# Crossover data


```{r read_Canyon-B_data_file}

GLODAP_CB <-
  read_csv(paste(path_preprocessing,
                 "GLODAPv2.2021_Canyon-B.csv",
                 sep = ""))

```

```{r define_cruises_to_check}

cruises_phosphate_gap_fill <-
  c("33MW19930704",
    "33RO20030604",
    "33RO20050111",
    "33RO19980123")

cruises_talk_gap_fill <-
  c("06AQ19980328")

cruises_tco2_calc <-
  c("35TH20040604",
    "29AH20160617")

cruises_talk_calc <-
  c("06MT19900123",
    "316N19920502",
    "316N19921006")


```





```{r prepare_additional_crossover_data}

xover_add_decade <- glodapv2_2021_xover_add %>%
  mutate(date_A = ymd(str_sub(cruise_A, 5, 12)),
         date_B = ymd(str_sub(cruise_B, 5, 12))) %>%
  mutate(decade = m_grid_decade(year(date_B))) %>%
  filter(!is.na(decade),
         !is.na(offset)) %>%
  arrange(date_B)

xover_add_decade %>%
  group_by(parameter, cruise_A) %>%
  summarise(offset_mean = mean(offset, na.rm = TRUE)) %>%
  ungroup() %>%
  kable(caption = "Long-term average per cruise and parameter") %>%
  kable_styling() %>%
  scroll_box(height = "250px")


xover_add_decade %>%
  group_by(parameter, decade, cruise_A) %>%
  summarise(offset_mean = mean(offset, na.rm = TRUE)) %>%
  ungroup() %>%
  kable(caption = "Decadal average per cruise and parameter") %>%
  kable_styling() %>%
  scroll_box(height = "250px")

xover_add_decade %>%
  filter(cruise_A %in% cruises_talk_calc,
         parameter == "talk") %>% 
  group_by(parameter, decade, cruise_A) %>%
  summarise(offset_mean = mean(offset, na.rm = TRUE)) %>%
  ungroup() %>%
  kable(caption = "Decadal talk average per cruise") %>%
  kable_styling() %>%
  scroll_box(height = "250px")

xover_add_decade %>%
  filter(cruise_A %in% cruises_talk_calc,
         parameter == "talk") %>% 
  group_by(parameter, decade) %>%
  summarise(offset_mean = mean(offset, na.rm = TRUE)) %>%
  ungroup() %>%
  kable(caption = "Decadal talk average") %>%
  kable_styling() %>%
  scroll_box(height = "250px")

xover_add_decade %>%
  filter(cruise_A %in% cruises_talk_calc,
         parameter == "talk") %>% 
  group_by(parameter) %>%
  summarise(offset_mean = mean(offset, na.rm = TRUE)) %>%
  ungroup() %>%
  kable(caption = "talk average") %>%
  kable_styling() %>%
  scroll_box(height = "250px")

xover_add_decade %>%
  filter(cruise_A %in% cruises_talk_calc,
         parameter == "talk") %>% 
  group_by(parameter, cruise_A) %>%
  summarise(offset_mean = mean(offset, na.rm = TRUE)) %>%
  ungroup() %>%
  kable(caption = "talk average per cruise") %>%
  kable_styling() %>%
  scroll_box(height = "250px")



hline_intercept <-
  tibble(parameter = unique(xover_add_decade$parameter)) %>%
  mutate(intercept = if_else(parameter %in% c("phosphate"),
                             1,
                             0))

p_crossover_ts <- xover_add_decade %>%
  ggplot(aes(date_B, offset)) +
  geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
  geom_point(shape = 21) +
  scale_color_brewer(palette = "Set1") +
  facet_grid(parameter ~ ., scales = "free_y") +
  theme(
    legend.position = "bottom",
    legend.direction = "vertical",
    axis.title.x = element_blank()
  )

p_crossover_decadal <-
  ggplot() +
  geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
  geom_violin(data = xover_add_decade,
               aes(x = decade, y = offset), fill="gold") +
  geom_boxplot(data = xover_add_decade,
               aes(x = decade, y = offset),
               width = 0.2) +
  facet_grid(parameter ~ ., scales = "free_y") +
  labs(title = "Decadal offsets") +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90))


p_crossover_ts + p_crossover_decadal +
  plot_layout(widths = c(2, 1))

```



## Gap filling


```{r CANYON-B_gap_filling}

GLODAP <- left_join(GLODAP,
                    GLODAP_CB %>% 
                      select(row_number, ends_with("_CANYONB")))

# fill missing phosphate with CANYON-B estimate

GLODAP_phosphate_fill <- GLODAP %>%
  filter(cruise_expocode %in% cruises_phosphate_gap_fill,
         is.na(phosphate),
         oxygenqc == 1)

GLODAP_phosphate_fill <- GLODAP_phosphate_fill %>% 
  mutate(phosphate = phosphate_CANYONB) %>% 
  filter(!is.na(phosphate))

map +
  geom_tile(data = GLODAP_phosphate_fill %>%
              distinct(lon, lat, cruise_expocode),
            aes(lon, lat, fill = cruise_expocode)) +
  scale_fill_brewer(palette = "Set1")



for (i_cruise in cruises_phosphate_gap_fill) {
  # i_cruise <- cruises_phosphate_gap_fill[1]
  
  p_crossover_ts <- xover_add_decade %>%
    filter(cruise_A %in% i_cruise) %>%
    ggplot(aes(date_B, offset)) +
    geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
    geom_point(shape = 21) +
    scale_color_brewer(palette = "Set1") +
    facet_grid(parameter ~ ., scales = "free_y") +
    labs(title = i_cruise) +
    theme(
      legend.position = "bottom",
      legend.direction = "vertical",
      axis.title.x = element_blank()
    )
  
  p_crossover_decadal <-
    ggplot() +
    geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
    geom_violin(
      data = xover_add_decade %>%
        filter(cruise_A %in% i_cruise),
      aes(x = decade, y = offset),
      fill = "gold"
    ) +
    geom_boxplot(
      data = xover_add_decade %>%
        filter(cruise_A %in% i_cruise),
      aes(x = decade, y = offset),
      width = 0.2
    ) +
    facet_grid(parameter ~ ., scales = "free_y") +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_text(angle = 90))
  
  print(
  p_crossover_ts + p_crossover_decadal +
    plot_layout(widths = c(2, 1))
  )
  
}

# fill missing talk with CANYON-B estimate

GLODAP_talk_fill <- GLODAP %>%
  filter(cruise_expocode %in% cruises_talk_gap_fill,
         is.na(talk),
         oxygenqc == 1)

GLODAP_talk_fill <- GLODAP_talk_fill %>% 
  mutate(talk = talk_CANYONB) %>% 
  filter(!is.na(talk))


map +
  geom_tile(data = GLODAP_talk_fill %>%
              distinct(lon, lat, cruise_expocode),
            aes(lon, lat, fill = cruise_expocode)) +
  scale_fill_brewer(palette = "Set1")



for (i_cruise in cruises_talk_gap_fill) {
  # i_cruise <- cruises_phosphate_gap_fill[1]
  
  p_crossover_ts <- xover_add_decade %>%
    filter(cruise_A %in% i_cruise) %>%
    ggplot(aes(date_B, offset)) +
    geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
    geom_point(shape = 21) +
    scale_color_brewer(palette = "Set1") +
    facet_grid(parameter ~ ., scales = "free_y") +
    labs(title = i_cruise) +
    theme(
      legend.position = "bottom",
      legend.direction = "vertical",
      axis.title.x = element_blank()
    )
  
  p_crossover_decadal <-
    ggplot() +
    geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
    geom_violin(
      data = xover_add_decade %>%
        filter(cruise_A %in% i_cruise),
      aes(x = decade, y = offset),
      fill = "gold"
    ) +
    geom_boxplot(
      data = xover_add_decade %>%
        filter(cruise_A %in% i_cruise),
      aes(x = decade, y = offset),
      width = 0.2
    ) +
    facet_grid(parameter ~ ., scales = "free_y") +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_text(angle = 90))
  
  print(p_crossover_ts + p_crossover_decadal +
          plot_layout(widths = c(2, 1)))
  
}


GLODAP_gap_fill <- bind_rows(
  GLODAP_phosphate_fill,
  GLODAP_talk_fill
)

```

## Flagging

```{r flagged_cruises}


GLODAP_tco2_calc <- GLODAP %>% 
  filter(cruise_expocode %in% cruises_tco2_calc,
         tco2f == 0)


map +
  geom_tile(data = GLODAP_tco2_calc %>%
              distinct(lon, lat, cruise_expocode),
            aes(lon, lat, fill = cruise_expocode)) +
  scale_fill_brewer(palette = "Set1")



for (i_cruise in cruises_tco2_calc) {
  # i_cruise <- cruises_phosphate_gap_fill[1]
  
  p_crossover_ts <- xover_add_decade %>%
    filter(cruise_A %in% i_cruise) %>%
    ggplot(aes(date_B, offset)) +
    geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
    geom_point(shape = 21) +
    scale_color_brewer(palette = "Set1") +
    facet_grid(parameter ~ ., scales = "free_y") +
    labs(title = i_cruise) +
    theme(
      legend.position = "bottom",
      legend.direction = "vertical",
      axis.title.x = element_blank()
    )
  
  p_crossover_decadal <-
    ggplot() +
    geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
    geom_violin(
      data = xover_add_decade %>%
        filter(cruise_A %in% i_cruise),
      aes(x = decade, y = offset),
      fill = "gold"
    ) +
    geom_boxplot(
      data = xover_add_decade %>%
        filter(cruise_A %in% i_cruise),
      aes(x = decade, y = offset),
      width = 0.2
    ) +
    facet_grid(parameter ~ ., scales = "free_y") +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_text(angle = 90))
  
  print(p_crossover_ts + p_crossover_decadal +
          plot_layout(widths = c(2, 1)))
  
}


GLODAP_talk_calc <- GLODAP %>% 
  filter(cruise_expocode %in% cruises_talk_calc,
         talkf == 0)


map +
  geom_tile(data = GLODAP_talk_calc %>%
              distinct(lon, lat, cruise_expocode),
            aes(lon, lat, fill = cruise_expocode)) +
  scale_fill_brewer(palette = "Set1")



for (i_cruise in cruises_talk_calc) {
  # i_cruise <- cruises_phosphate_gap_fill[1]
  
  p_crossover_ts <- xover_add_decade %>%
    filter(cruise_A %in% i_cruise) %>%
    ggplot(aes(date_B, offset)) +
    geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
    geom_point(shape = 21) +
    scale_color_brewer(palette = "Set1") +
    facet_grid(parameter ~ ., scales = "free_y") +
    labs(title = i_cruise) +
    theme(
      legend.position = "bottom",
      legend.direction = "vertical",
      axis.title.x = element_blank()
    )
  
  p_crossover_decadal <-
    ggplot() +
    geom_hline(data = hline_intercept, aes(yintercept = intercept)) +
    geom_violin(
      data = xover_add_decade %>%
        filter(cruise_A %in% i_cruise),
      aes(x = decade, y = offset),
      fill = "gold"
    ) +
    geom_boxplot(
      data = xover_add_decade %>%
        filter(cruise_A %in% i_cruise),
      aes(x = decade, y = offset),
      width = 0.2
    ) +
    facet_grid(parameter ~ ., scales = "free_y") +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_text(angle = 90))
  
  print(
  p_crossover_ts + p_crossover_decadal +
    plot_layout(widths = c(2, 1))
  )
    
}


GLODAP_calc <- bind_rows(
  GLODAP_tco2_calc,
  GLODAP_talk_calc
)

  
```

## Write files

```{r write_files_for_crossover}

GLODAP_crossover <- bind_rows(
  GLODAP_gap_fill,
  GLODAP_calc
) 

GLODAP_crossover_write <- GLODAP_crossover %>% 
  select(
    EXPOCODE = cruise_expocode,
    STNNBR = station,
    CASTNO = cast,
    BTLNBR = bottle,
    DATE = date,
    LATITUDE = lat,
    LONGITUDE = lon,
    CTDPRS = pressure,
    CTDTMP = temp,
    CTDSAL = sal,
    CTDSAL_FLAG_W = salinityf,
    PHSPHT = phosphate,
    PHSPHT_FLAG_W = phosphatef,
    TCARBN = tco2,
    TCARBN_FLAG_W = tco2f,
    ALKALI = talk,
    ALKALI_FLAG_W = talkf)

GLODAP_crossover_write <- GLODAP_crossover_write %>% 
  mutate(DATE = format(DATE,  "%Y%m%d"))


last_line <- "END_DATA"

for (i_EXPOCODE in unique(GLODAP_crossover_write$EXPOCODE)) {
  # i_EXPOCODE <- unique(GLODAP_crossover_write$EXPOCODE)[1]
  
  temp <- GLODAP_crossover_write %>%
    filter(EXPOCODE == i_EXPOCODE) %>%
    add_row(.before = 1)
  
  cat("Bottle",
      "\n",
      file = paste0(
        path_preprocessing,
        "crossover_cruises/",
        i_EXPOCODE,
        ".exc.csv"
      )
    )
  
  temp %>%
    write_csv(
      file = paste0(
        path_preprocessing,
        "crossover_cruises/",
        i_EXPOCODE,
        ".exc.csv"
      ),
      na = "",
      append = TRUE,
      col_names = TRUE
    )
  
  write(
    last_line,
    file = paste0(
      path_preprocessing,
      "crossover_cruises/",
      i_EXPOCODE,
      ".exc.csv"
    ),
    append = TRUE
  )
  
  
}





```


